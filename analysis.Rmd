---
title: "Idaho antibiotic use"
author:
    - Jeremy Boyd, Ph.D.
    - jeremyboyd@pm.me
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
    html_document:
        theme: spacelab
        toc: true
        toc_float: true
---

```{r setup, include = FALSE}

# Make default image type SVG
knitr::opts_chunk$set(dev = "svg")

```

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Read in provider type bank
p_types <- read_feather("Idaho provider type bank.feather") %>%
    select(Prscrbr_Type, Std_Provider_Type)

# Read in address-county info
address_county <- read_feather("Address-query-county bank.feather")

# By-provider dataset
p <- read_feather("Idaho prescribers by provider data.feather") %>%
    mutate(Bene_Prop_Fem = Bene_Feml_Cnt / Tot_Benes,
           Bene_Prop_White = Bene_Race_Wht_Cnt / Tot_Benes,
           Prscrbr_RUCA = floor(Prscrbr_RUCA),
           Prscrbr_RUCA_fct = factor(Prscrbr_RUCA),
           dataset_address = str_squish(
                paste(Prscrbr_St1,
                      Prscrbr_St2,
                      Prscrbr_City,
                      Prscrbr_State_Abrvtn,
                      Prscrbr_Zip5))) %>%
    
    # Standardized prescriber types
    left_join(p_types, by = c("Prscrbr_Type")) %>%
    
    # County info
    left_join(address_county %>%
                  select(dataset_address, county),
              by = "dataset_address") %>%
    select(Year = year,
           Prscrbr_NPI,
           Prscrbr_Type_Std = Std_Provider_Type,
           Prscrbr_RUCA,
           Prscrbr_RUCA_fct,
           Prscrbr_Gndr,
           Prscrbr_State_Abrvtn,
           Prscrbr_County = county,
           Antbtc_Tot_Clms,
           Tot_Benes,
           Bene_Avg_Age,
           Bene_Avg_Risk_Scre,
           Bene_Prop_Fem,
           Bene_Prop_White,
           dataset_address)

```

<br>

***

# The by-provider dataset

The *Medicare Part D Prescribers - by Provider dataset* is publically-available [here](https://data.cms.gov/provider-summary-by-type-of-service/medicare-part-d-prescribers/medicare-part-d-prescribers-by-provider). Each row in the dataset gives prescribing information for a particular provider in a particular year. The present work focuses on rows representing Idaho providers in all available dataset years (currently `r min(p$year)`-`r max(p$year)`). This amounts to `r format(nrow(p), big.mark = ",")` rows.

The main focus of the study is on antibiotic prescribing behavior. Consequently, we are interested in the number of antibiotic claims providers have, and on variables that may be useful in predicting antibiotic claims. A subset of rows illustrating these data are shown below in Table 1.

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

set.seed(1)
p %>%
    sample_n(10) %>%
    mutate(across(where(is.numeric), ~ round(., digits = 2))) %>%
    datatable(caption = "Table 1: Example rows from the by-providers dataset.",
              rownames = FALSE,
              options = list(dom = "t"))

# Drop rows missing claims, impute Tot_Benes
p2 <- p %>%
    filter(!is.na(Antbtc_Tot_Clms),
           Antbtc_Tot_Clms >= 11) %>%
    mutate(Tot_Benes = if_else(is.na(Tot_Benes), 10, Tot_Benes),
           claims_1k = Antbtc_Tot_Clms / (Tot_Benes / 1000),
           log_claims_1k = log(claims_1k))

p3 <- p2 %>%
    filter(!is.na(Bene_Prop_Fem),
           !is.na(Bene_Prop_White),
           !is.na(Prscrbr_RUCA))

```

- Drop missing claims
- Impute missing beneficiaries (after Guion?)
- Drop remaining missing values--X percent that are missing either fem or white.


Note that many rows are missing values, including a number that are missing the outcome variable--Antbtc_Tot_Clms--and the number of beneficiaries--Tot_Benes. These variable are surpressed for counts of claims or beneficiaries less than 11.




After excluding rows missing either of these variables, the dataset consists of `r format(nrow(p2), big.mark = ",")` rows.





Table 2 summarizes missingness in the by-providers dataset for the State of Idaho from `r min(p$year)` to `r max(p$year)`.

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Summarize_all superseded by summarize(across(...))

p3 %>%
    summarize_all(~ sum(is.na(.)) / n()) %>%
    pivot_longer(cols = everything(), names_to = "column",
                 values_to = "p_missing") %>%
    arrange(desc(p_missing)) %>%
    mutate(across(where(is.numeric), ~ round(., digits = 4))) %>%
    datatable(caption = "Table 2: Proportion of data missing across various columns.",
              rownames = FALSE,
              options = list(dom = "t",
                             pageLength = ncol(p3)))

```

Both Antbtc_Tot_Clms and Tot_Benes need to be defined in order to compute each provider's claims per beneficiary. Missing values of Tot_Benes were imputed as 10. Rows missing Antbtc_Tot_Clms were excluded from analysis.


```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Better way to talk about this is that we have certain columns we're interested in retaining for modeling purposes. For these cols we impute some missing values, and exclude rows with others. Just say how many rows were lost out of the total, and that mostly this was due to missing claims.

# We start out with X rows.

# We're left with Y rows. We lose W rows due to missing claims, plus another Z rows due to missing fem/white.


# After dropping missing claims stuf, only 10 and 8% missingness in fem and white.
# p2 %>%
#     summarize_all(~ sum(is.na(.)) / n()) %>%
#     pivot_longer(cols = everything(), names_to = "column",
#                  values_to = "p_missing") %>%
#     arrange(desc(p_missing)) %>%
#     mutate(across(where(is.numeric), ~ round(., digits = 2))) %>%
#     datatable(caption = "Table 2: Proportion of data missing across various columns.",
#               rownames = FALSE,
#               options = list(dom = "t",
#                              pageLength = ncol(p)))

# Read in generic drug bank
generics <- read_feather("Generic drug bank.feather")

# Read in by-provider-and-drug dataset. This has claims numbers for computing
# claims per 1K beneficiaries.
pd <- read_feather("Idaho prescribers by provider & drug data.feather") %>%
    
    # Join in coding for drug classes from generics
    left_join(generics, by = "Gnrc_Name") %>%
    select(Prscrbr_NPI, year, Gnrc_Name, Tot_Clms, Antibiotic:Other)
    
# Read in by-provider dataset. This has beneficiary numbers for computing claims
# per 1K beneficiaries. Join in prescriber type (only have this for 2019 so
# far).
# %>%
    
    # Join county
    # left_join(add2, by = "dataset_address")
    
# List of ~ 1K addresses curently missing counties
# p %>% filter(is.na(county)) %>%
#     select(dataset_address) %>%
#     unique()

```


### Counts of providers per year

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Counts of providers per year
p %>%
    count(Year)
```

### No missing provider type info

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}
# There's no missing provider type info
p %>%
    select(Year, Prscrbr_Type_Std) %>%
    group_by(Year) %>%
    summarize_all(~ sum(is.na(.)) / n())

```

### What the basic data look like

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Separate into tables based on whether Tot_Benes is defined or not
# yes_benes <- p %>% filter(!is.na(Tot_Benes))
# no_benes <- p %>% filter(is.na(Tot_Benes))
# 
# # For NA values, impute
# # NOTE: Can we also impute values for other cols? Most of these are subject to
# # the > 10 beneficiary rule.
# set.seed(1)
# no_benes$Tot_Benes_Imp <- round(rnorm(n = nrow(no_benes), mean = 5.5, sd = 1.5))
# no_benes <- no_benes %>%
#     mutate(Tot_Benes_Imp = case_when(
#         Tot_Benes_Imp > 10 ~ 10,
#         Tot_Benes_Imp < 1 ~ 1,
#         TRUE ~ Tot_Benes_Imp))
# 
# # Recombine to form p_benes with imputed values for NA Tot_Benes
# p <- bind_rows(yes_benes, no_benes) %>%
#     mutate(percent_fem = Bene_Feml_Cnt / Tot_Benes * 100,
#            percent_fem_imp = Bene_Feml_Cnt / Tot_Benes_Imp * 100)

# Drug classes that we want to compute claims per 1K beneficiaries for
drug_classes <- names(generics)[2:length(names(generics))]

# Cross every provider NPI appearing in 2013-2019 p data with each year from
# 2013-2019 with all 11 drug classes.
crossed <- expand_grid(year = unique(p$Year),
                          class = drug_classes,
                          Prscrbr_NPI = unique(p$Prscrbr_NPI))

# Summarize total claims per provider per year per drug class from pd
pd2 <- map_dfr(drug_classes, function(class) {
    message(paste0("Getting claim data for class ", class, "..."))
    pd %>%
        filter(!!sym(class) == 1) %>%
        group_by(Prscrbr_NPI, year) %>%
        dplyr::summarize(
            n_drugs = sum(!is.na(Tot_Clms)),
            n_na_tot_clms = sum(is.na(Tot_Clms)),
            tot_clms = sum(Tot_Clms, na.rm = TRUE),
            .groups = "drop") %>%
        mutate(class = class) })

# Join summarized claims data to crossed
pd3 <- crossed %>%
    left_join(pd2, by = c("Prscrbr_NPI", "year", "class"))

# Join pd3 to p
# p2 <- p %>%
#     left_join(pd3, by = c("Prscrbr_NPI", "year")) %>%
#     mutate(tot_clms = if_else(is.na(tot_clms), 0, tot_clms),
#            claims_1k = tot_clms / (Tot_Benes / 1000),
#            claims_ben_ratio = tot_clms / Tot_Benes,
#            log_claims_1k = log(claims_1k),
#            log_claims_1k_one = log(claims_1k + 1))
    

# Get min nonzero claims_1k by class by year
# mins <- p2 %>%
#     filter(claims_1k != 0) %>%
#     group_by(year, class) %>%
#     dplyr::summarize(claims_1k_min = min(claims_1k, na.rm = TRUE),
#                      .groups = "drop")

# Join in min nonzero values
# p3 <- p2 %>%
#     left_join(mins, by = c("year", "class")) %>%
#     mutate(log_claims_1k_half_min = log(claims_1k + claims_1k_min / 2))



# 
#     pd %>%
#         filter(!!sym(class) == 1) %>%
#         group_by(.drop = FALSE) %>%
#         group_by(Prscrbr_NPI, year) %>%
#         dplyr::summarize(
#             n_drugs = sum(!is.na(Tot_Clms)),
#             n_na_tot_clms = sum(is.na(Tot_Clms)),
#             tot_clms = sum(Tot_Clms, na.rm = TRUE), .groups = "drop") %>%
#         mutate(class = class) %>%
#         right_join(p, by = c("Prscrbr_NPI", "year")) }) %>%
#     mutate(tot_clms = if_else(is.na(tot_clms), 0, tot_clms),
#            claims_1k = tot_clms / (Tot_Benes / 1000),
#            claims_1k_imp = tot_clms / (Tot_Benes_Imp / 1000),
#            
#            # NOTE: We now have lots of zeros, and log(0) is undefined. Model as
#            # proportion data (negative binomial?) since that's actually what it is.
#            log_claims_1k = log(claims_1k),
#            log_claims_1k_imp = log(claims_1k_imp))
# 
# # Summarize across drugs to get total claims per drug *class*. Join in
# # beneficiary data.
# p2 <- map_dfr(drug_classes, function(class) {
#     message(paste0("Getting claim data for class ", class, "..."))
#     pd %>%
#         filter(!!sym(class) == 1) %>%
#         # filter(Antibiotic == 1) %>%
#         # filter(Tetracycline == 1) %>%
#         group_by(.drop = FALSE) %>%
#         group_by(Prscrbr_NPI, year) %>%
#         dplyr::summarize(
#             n_drugs = sum(!is.na(Tot_Clms)),
#             n_na_tot_clms = sum(is.na(Tot_Clms)),
#             tot_clms = sum(Tot_Clms, na.rm = TRUE), .groups = "drop") %>%
#         mutate(class = class)
# })
#     
#     %>%
#         right_join(p, by = c("Prscrbr_NPI", "year")) }) %>%
#     mutate(tot_clms = if_else(is.na(tot_clms), 0, tot_clms),
#            claims_1k = tot_clms / (Tot_Benes / 1000),
#            claims_1k_imp = tot_clms / (Tot_Benes_Imp / 1000),
#            
#            # NOTE: We now have lots of zeros, and log(0) is undefined. Model as
#            # proportion data (negative binomial?) since that's actually what it is.
#            log_claims_1k = log(claims_1k),
#            log_claims_1k_imp = log(claims_1k_imp))

# p2 has one row per provider per year per drug class
# p3 %>% count(class, year)
# p3 %>% count(year, class)

# Example prescriber: for 2013 we have rows for each drug class. Tot_Benes is always the same because it doesn't change over a year. tot_clms is per drug class.
# NAs here mean that the join of pd to p by NPI & year failed. We keep the columns from p (npi, year, benes) but we get NA for the cols from pd (class & tot_clms). Doesn't make sense. If the join worked...
# A provider never provided an rx for drug X in 2019. That means there won't be a row for the drug in pd 2019. So when you try to join that to p you'll get NA
# p3 %>%
#     filter(Prscrbr_NPI == "1003012204", year == 2013) %>%
#     dplyr::select(Prscrbr_NPI, year, class, tot_clms, Tot_Benes)
# 
# # Same story for 2014
# p3 %>%
#     filter(Prscrbr_NPI == "1003012204", year == 2014) %>%
#     dplyr::select(Prscrbr_NPI, year, class, tot_clms, Tot_Benes) %>%
#     arrange(year, class)
# 
# # Same story for 2019
# p3 %>%
#     filter(Prscrbr_NPI == "1003012204", year == 2019) %>%
#     dplyr::select(Prscrbr_NPI, year, class, tot_clms, Tot_Benes) %>%
#     arrange(year, class)

```

### Source of the numerator in claims / 1K beneficiaries

A recent report by Gouin and colleagues (2022) based on Medicare Part D data shows antibiotics claims of ~ 400 per 1K beneficiaries. In contrast, I'm seeing numbers closer to ~ 200 per 1K. Most of this seems to be related to the dataset that claims numbers are coming from. In Gouin et al. they're taking claims numbers from the by-provider dataset. In this dataset, each row represents a provider, and a column labeled Antbtc_Tot_Clms gives all of the antibiotic claims that provider has for the given year. In contrast, I'm taking claims numbers from the by-provider-and-drug dataset. For this dataset, each row gives info for a particular provider for a particular drug. We identify all of drugs that are antibiotics and add up the claims to get a total number of antibiotic claims a provider has in a given year.

Crucially for the by-provider-and-drug dataset, rows with < 11 claims are *not included*. This means that we're missing claims. This isn't as big an issue in the by-provider dataset because (1) the antibiotic count is aggregated across lots of different drugs, so the numbers are more often >= 11, and (2) even when the number is lower, rows with NA *are included*. This allows for imputation.

In the figure below I show that antibiotic claims per 1K beneficiaries is quite a bit lower when the numerator (the number of claims) comes from the by-provider-and-drug dataset (pd) versus the by-provider dataset (p).

This isn't necessarily a problem--just need to explain how we're computing the stat. The way we're doing it is giving us the ability to break out different kinds of antibiotics, but at the expense of missing rows, which means we're consistently underestimating.

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Comparison between x and y shows that mean claims / 1K is higher when computing with the number of antibiotic claims from the by-providers dataset (x) than the by-providers-and-drug dataset (y). This is probably why my numbers seem lower than what's reported in Gouin (2022). Find out how the Antbtc_Tot_Clms column is computed in the by-providers dataset. Want to try to approximate what it's doing as closely as possible when getting numerators from by-provider-and-drug. Also, are we correctly coding for all antibiotics in by-provider-and-drug? Looks like the number of prescribers and beneficiaries is the same across the two datasets, but the number of claims is quite a bit lower when we take it from provider-by-drug, leading to lower claims per 1k beneficiaries. Probably one thing that's going on is that we lose all rows in provider-by-drug that are < 11. So that pushes our claim counts lower. Not as much of an issue in by-provider because the antibiotic claim counts get aggregated to much larger numbers, so fewer < 11. And we can't impute in the pd table since the rows that would have NAs have been removed before we get to it.
p_vs_pd_num <- bind_rows(
    p %>%
        mutate(Tot_Benes = if_else(is.na(Tot_Benes), 10, Tot_Benes),
               numerator = "p") %>%
        group_by(year, numerator) %>%
        dplyr::summarize(
            n_prscrbr = sum(!is.na(Prscrbr_NPI)),
            n_benes = sum(Tot_Benes, na.rm = TRUE),
            n_claims = sum(Antbtc_Tot_Clms, na.rm = TRUE),
            mean_benes = mean(Tot_Benes, na.rm = TRUE),
            mean_claims = mean(Antbtc_Tot_Clms, na.rm = TRUE),
            mean_claims_1k = mean(Antbtc_Tot_Clms / (Tot_Benes / 1000),
                                  na.rm = TRUE),
            .groups = "drop"),
    p3 %>%
        filter(class == "Antibiotic") %>%
        mutate(Tot_Benes = if_else(is.na(Tot_Benes), 10, Tot_Benes),
               numerator = "pd") %>%
        group_by(year, numerator) %>%
        dplyr::summarize(
            n_prscrbr = sum(!is.na(Prscrbr_NPI)),
            n_benes = sum(Tot_Benes, na.rm = TRUE),
            n_claims = sum(tot_clms, na.rm = TRUE),
            mean_benes = mean(Tot_Benes, na.rm = TRUE),
            mean_claims = mean(tot_clms, na.rm = TRUE),
            mean_claims_1k = mean(tot_clms / (Tot_Benes / 1000),
                                  na.rm = TRUE),
            .groups = "drop"))

# Fewer claims when summarized from the by-provider-and-drug table versus the by-provider table.
p_vs_pd_num %>%
    ggplot(aes(
        x = year,
        y = mean_claims,
        group = numerator,
        color = numerator)) +
    geom_line()

# Mean number of beneficiaries. These are identical because we're always taking
# the number of beneficiaries from the by-provider table.
posd = position_dodge(0.4)
p_vs_pd_num %>%
    ggplot(aes(
        x = year,
        y = mean_benes,
        group = numerator,
        color = numerator)) +
    geom_line(position = posd) +
    labs(subtitle = str_wrap("Beneficiary numbers don't vary--always from the by-providers table", 40))

# Lower mean claims / 1k beneficiaries when claims come from the by-provider-and-drug table versus the by-provider table.
p_vs_pd_num %>%
    ggplot(aes(
        x = year,
        y = mean_claims_1k,
        group = numerator,
        color = numerator)) +
    geom_line()

```

## Summary tables for beneficiaries and use

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}


```

### Beneficiary tables for antibiotics and cephalosporin by year

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}
# Beneficiary table by year
p3 %>%
    filter(class == "Antibiotic") %>%
    rename(Year = year) %>%
    compute_summary_table(group = "Year") %>%
    format_ben_table()

# Beneficiary data stays the same, regardless of the class of antibiotics chosen
p3 %>%
    filter(class == "Cephalosporin") %>%
    rename(Year = year) %>%
    compute_summary_table(group = "Year") %>%
    format_ben_table()
```

### 2019 beneficiary summaries by provider type

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# 2019 beneficiary table by provider type
p3 %>%
    filter(class == "Antibiotic", year == 2019) %>%
    rename(`Provider Type` = Std_Provider_Type) %>%
    compute_summary_table(group = "Provider Type") %>%
    format_ben_table()

# Again, beneficiary data stays the same, regardless of drug class
p3 %>%
    filter(class == "Cephalosporin", year == 2019) %>%
    rename(`Provider Type` = Std_Provider_Type) %>%
    compute_summary_table(group = "Provider Type") %>%
    format_ben_table()

```

### Antibiotic & Cephalosporin use by year

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Use table by year
p3 %>%
    filter(class == "Antibiotic") %>%
    rename(Year = year) %>%
    compute_summary_table(group = "Year") %>%
    format_use_table()

# Mean beneficiary count stays the same by year, but other cols change with a
# different drug.
p3 %>%
    filter(class == "Cephalosporin") %>%
    rename(Year = year) %>%
    compute_summary_table(group = "Year") %>%
    format_use_table()
```

### 2019 Antibiotic use by provider type

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# 2019 use table by provider type
p3 %>%
    filter(class == "Antibiotic", year == 2019) %>%
    rename(`Provider Type` = Std_Provider_Type) %>%
    compute_summary_table(group = "Provider Type") %>%
    format_use_table()

```

### Comparison of weighted versus unweighted means

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Number of providers per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    ggplot(mapping = aes(x = year, y = n_prscrbr)) +
    geom_line()
               
# Mean beneficiaries by year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    ggplot(mapping = aes(x = year, y = mean_ben)) +
    geom_line() +
    geom_errorbar(aes(ymin = mean_ben - sd_ben,
                      ymax = mean_ben + sd_ben),
                  width = 0.2,
                  size = 0.5)

# Mean beneficiary age per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_age_wt, mean_age_unwt) %>%
    pivot_longer(cols = matches("mean_age"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean % female per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_fem_wt, mean_fem_unwt) %>%
    pivot_longer(cols = matches("mean_fem"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean hcc per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_hcc_wt, mean_hcc_unwt) %>%
    pivot_longer(cols = matches("mean_hcc"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean claims per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_claims_wt, mean_claims_unwt) %>%
    pivot_longer(cols = matches("mean_claims"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean claims per 1k beneficiaries per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_claims_1k_wt, mean_claims_1k_unwt) %>%
    pivot_longer(cols = matches("mean_claims"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

```

### claims_1k ~ year for each drug class

CIs currently show 95% quantiles. Want to change this to a bootstrapped 95% CI on the mean.

Models are OLS of claims_1k ~ year, which is not normally distributed. Looks like it's mostly zeros and probably over-dispersed.

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.height = 8, fig.width = 11}

# Copy dataset

# Create y response variable. y will be interpreted as the proportion of all beneficiaries that were prescribed the drug
# p3$y <- cbind(p2$tot_clms, p2$Tot_Benes)

# Model y as binomially-distributed function of year
# fit <- glm(y ~ year, data = p3 %>% filter(class == "Antibiotic"), family = "binomial")

# Not at all normal
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = claims_1k)) +
    geom_density()

# Shows that from 50-99% of providers per year per drug have zero claims per 1k beneficiaries. So if you're interested in measuring claims per 1k out of all providers with a claim then you really don't want to log because you're dropping tons of data. If, on the other hand, you're interested in claims / 1k out of providers with *antibiotic* claims only, then it might work because you won't have any zeros.
zeros <- p3 %>%
    group_by(year, class) %>%
    summarize(n_prv_zero = sum(claims_1k == 0, na.rm = TRUE),
              n_prv_nonzero = sum(claims_1k > 0, na.rm = TRUE),
              .groups = "drop") %>%
    mutate(p_zero = n_prv_zero / (n_prv_zero + n_prv_nonzero))


# Problem with logging is that you drop all of the zeros, which are potentially informative.
# p3 %>%
#     filter(class == "Antibiotic") %>%
#     ggplot(aes(x = log_claims_1k)) +
#     geom_density()
# 
# # Number of providers in the by-provider data
# p %>%
#     select(Prscrbr_NPI) %>%
#     unique() %>%
#     nrow()

# Number of providers in the by-provider-and-drug data, who also have an antibiotic claim. For all years we have about half of providers who didn't prescribe an antibiotic. Shouldn't they be included?
# pd %>%
#     filter(Antibiotic == 1) %>%
#     select(Prscrbr_NPI) %>%
#     unique() %>%
#     nrow()

# Models of claims_1k ~ year, normal distribution
year_effects <- map_dfr(drug_classes, function(class) {
    class_data <- p3 %>%
        filter(class == !!class)
    lm(claims_1k ~ year,
       data = class_data,
       weights = Tot_Benes) %>%
    tidy() %>%
    mutate(class = class)
}) %>%
    mutate(
        `p < 0.05` = if_else(p.value < 0.05, "*", "")) %>%
    filter(term == "year") %>%
    arrange(p.value)

# Models of claims_1k ~ year, binomial distribution
# year_effects_binomial <- map_dfr(drug_classes, function(class) {
#     class_data <- p2 %>%
#         filter(class == !!class)
#     glm(claims_1k ~ year,
#        data = class_data,
#        weights = Tot_Benes) %>%
#     tidy() %>%
#     mutate(class = class)
# }) %>%
#     mutate(
#         `p < 0.05` = if_else(p.value < 0.05, "*", "")) %>%
#     filter(term == "year") %>%
#     arrange(p.value)

# Compute percent change from 2013 to 2019 (negative is decrease)
change <- map_dfr(drug_classes, function(class) {
    p3 %>%
        filter(class == !!class) %>%
        compute_summary_table(group = "year") %>%
        dplyr::select(year, class, mean_claims_1k_wt) %>%
        pivot_wider(names_from = "year", values_from = "mean_claims_1k_wt") %>%
        mutate(percent_change = -(`2013` - `2019`) / `2013` * 100)
})
    
# Weighted claims per 1k beneficiaries by year, where we're including providers
# who don't have any associated antibiotic claims, rather than only including
# those with >= 1 associated anbitiotic claim.
map_dfr(drug_classes, function(x) {
    p3 %>%
        filter(class == x) %>%
        compute_summary_table(group = "year") %>%
        select(year, class, mean_claims_1k_wt, se_claims_1k_wt,
               ci_claims_1k_lower, ci_claims_1k_upper, lower_ci_claims_1k_wt,
               upper_ci_claims_1k_wt)
}) %>%
    left_join(year_effects, by = "class") %>%
    left_join(change, by = "class") %>%
    mutate(class2 = case_when(
        `p < 0.05` == "*" & percent_change > 0 ~ paste0(
            class, "\n",
            round(percent_change), "% change\n",
            "p = ", format(p.value, scientific = TRUE, digits = 3)),
        `p < 0.05` == "*" & percent_change < 0 ~  paste0(
            class, "\n",
            round(percent_change), "% change\n",
            "p = ", format(p.value, scientific = TRUE, digits = 3)),
        TRUE ~ class),
        class2 = fct_relevel(class2, "Other", after = Inf)) %>%
    ggplot(mapping = aes(x = year, y = mean_claims_1k_wt, color = class2,
                         group = class2)) +
    geom_errorbar(aes(ymin = lower_ci_claims_1k_wt,
                      ymax = upper_ci_claims_1k_wt),
                  width = 0.2, size = 0.2, color = "gray50") +
    geom_line() +
    scale_y_continuous(limits = c(-20, 1000)) +
    facet_wrap(~ class2, ncol = 4, scales = "free") +
    labs(x = "Year",
         y = "Claims\nper 1K\nbeneficiaries",
         color = "Class") +
    theme(legend.position = "none")

```


### Claims 1k by provider type

- 2019 Antibiotic data.

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# map_dfr(drug_classes, function(x) {
#     p3 %>%
#         filter(class == x) %>%
#         compute_summary_table() %>%
#         select(
#             year,
#         class,
#         Std_Provider_Type,
#         mean_claims_1k_wt,
#         se_claims_1k_wt,
#         ci_claims_1k_lower,
#         ci_claims_1k_upper,
#         lower_ci_claims_1k_wt,
#         upper_ci_claims_1k_wt
#     ) }) %>%
#     ungroup() %>%
#     ggplot(mapping = aes(x = year, y = mean_claims_1k_wt,
#                          color = Std_Provider_Type, group = Std_Provider_Type)) +
#     geom_line() +
#     facet_wrap(~ Std_Provider_Type)
        
p3 %>%
    filter(class == "Antibiotic", year == 2019) %>%
    compute_summary_table(group = "Std_Provider_Type") %>%
    select(
        class,
        Std_Provider_Type,
        mean_claims_1k_wt,
        se_claims_1k_wt,
        ci_claims_1k_lower,
        ci_claims_1k_upper,
        lower_ci_claims_1k_wt,
        upper_ci_claims_1k_wt
    ) %>%
    ungroup() %>%
    mutate(Std_Provider_Type = fct_reorder(factor(Std_Provider_Type),
                                           mean_claims_1k_wt)) %>%
    ggplot(mapping = aes(x = Std_Provider_Type, y = mean_claims_1k_wt)) +
    geom_col() +
    coord_flip()

```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

### Missingness

# Assess missingness in p2. 83% missing for Std_Provider_Type, but that's because I've only applied it to 2019 data. Bene_Feml_Cnt (and consequently percent_fem) is missing in 26% of the data. Tot_Benes is missing 8.5% of the time. Risk socre is only missing in 1%. RUCA < 1%.
missing <- p2 %>%
    summarize_all(~ sum(is.na(.) | is.infinite(.)) / n()) %>%
    pivot_longer(cols = everything(), names_to = "column",
                 values_to = "p_missing") %>%
    arrange(desc(p_missing))
    
# Race counts are relatively complete for white (17% missing), but are missing
# at ~ 50% for all other categories(black, asian, hispanic, native american)
# missing %>%
#     filter(str_detect(column, "Race"))


# Check p. ~ 25% of Antbtc_Tot_Clms is missing per year. Tot_Benes is missing < 10% of the time per year (impute?), RUCA is missing < 1% per year, always have prescriber type (which means we should be able to get a standardized prescriber type everywehre, prescriber gender is always there. Beneficiary age is always there except for 8% missing in 2017. Beneficiarly female count is missing ~ 25% of the time per year (impute?), Risk score is almost always there, except for 8% missing in 2017. ARE THE 2017 missing for real, or is it a problem with how I'm processing the data?  Race white counts are missing ~ 10% of the time. Other race variables are missing ~ 50% of the time. Bene_Dual_Cnt is missing ~ 40% of the time
p3 %>%
    group_by(year) %>%
    summarize_all(~ sum(is.na(.) | is.infinite(.)) / n()) %>%
    mutate(across(where(is.double), ~ format(., digits = 2, nsmall = 2))) %>%
    datatable()

# Realistic opportunities for imputation: Tot_Benes, Female count/percent female. Maybe race white counts?

# Shows that we have no NAs in pd data. This is a bit misleading though, since instead of coding Tot_Clms < 11 as NA, they're just excluded from the dataset. This is probably the main factor that leads to lower claims counts in the pd dataset, and consequently lower claims per 1k beneficiaries when computing using the pd claims counts.
# pd2 %>%
#     group_by(year, class) %>%
#     summarize_all(~ sum(is.na(.)) / n()) %>%
#     summary()
```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

### Can we get claims per 1k beneficiaries to look normal?

# Not really.
# 
# Logging gets us close to normal, but with 77% data loss.


# All of these distributions are entirely non-normal.
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = claims_1k)) +
    geom_density()

# Logging improves normality, but you lose massive amounts of data
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = log_claims_1k)) +
    geom_density()

# Amount of data you lose when trying to take log(0)
(p3 %>%
    filter(log_claims_1k == -Inf) %>%
    nrow()) / nrow(p3)

# Distribution of log(claims_1k + 1)
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = log_claims_1k_one)) +
    geom_density()

# Distribution of log(claims_1k + .5 * minimum nonzero claims_1k)
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = log_claims_1k_half_min)) +
    geom_density()

```

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Pairs plot
# library(GGally)
# p2019.2 %>%
#     select(Antbtc_Tot_Clms:Prscrbr_Gndr, Bene_Avg_Age, Bene_Avg_Risk_Scre,
#            Std_Provider_Type, percent_fem, percent_white) %>%
#     select(where(is.numeric)) %>%
#     ggpairs()
# 
# # Hurdle model
# mh1 <- pscl::hurdle(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
#                         Prscrbr_RUCA +
#                         Prscrbr_Gndr +
#                         Bene_Avg_Age +
#                         Bene_Avg_Risk_Scre +
#                         Std_Provider_Type +
#                         percent_fem +
#                         percent_white,
#              data = p2019.2,
#              dist = "negbin")
# summary(mh1)
# 
# 
# zinb1 <- pscl::zeroinfl(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
#                         Prscrbr_RUCA +
#                         Prscrbr_Gndr +
#                         Bene_Avg_Age +
#                         Bene_Avg_Risk_Scre +
#                         Std_Provider_Type +
#                         percent_fem +
#                         percent_white,
#              data = p2019.2,
#              dist = "negbin")
# summary(zinb1)

# Poisson
pois1 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Age +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = poisson)
summary(pois1)

# Intercept-only qpois model
qpois0 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1,
             data = p2019.2,
             family = quasipoisson)

# Quasi-poisson to get dispersion parameter. Indicates over-dispersion
qpois1 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Age +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois1)
anova(qpois1, test = "Chisq")

# Negative binomial
nb1 <- glm.nb(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Age +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2)
summary(nb1)

# Add fitted to visualize fit to empirical
p2019.2$pred_pois <- fitted(pois1)
p2019.2$pred_qpois0 <- fitted(qpois0)
p2019.2$pred_qpois1 <- fitted(qpois1)
p2019.2$pred_nb <- fitted(nb1)

# Visualize distribution of claims for empirical and models. Poisson is
# overplotted by quasipoisson--they have the same parameter values. But SEs are
# larger for quasi, which is supposed to be good, I think. Both quasipoisson and
# nb look like pretty good fits, with quasi maybe being a tad better. SEs larger for quasi versus nb. Significance is the same for quasi vs. nb. Parameter values are all similar.
p2019.2 %>%
    dplyr::select(empirical = Antbtc_Tot_Clms, matches("^pred_")) %>%
    pivot_longer(cols = matches("empirical|^pred_"), names_to = "source",
                 values_to = "tot_clms") %>%
    ggplot(aes(x = tot_clms, color = source)) +
    geom_density()

# Model fit isn't statistically different without age
qpois2 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois2)
anova(qpois1, qpois2, test = "Chisq")

# Model fit is statistically worse without risk score
qpois3 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
anova(qpois2, qpois3, test = "Chisq")

# Model fit is marginally worse (p = 0.12) without percent_fem
qpois4 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois4)
anova(qpois2, qpois4, test = "Chisq")

# Model fit is statistically worse without percent_white
qpois5 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem,
             data = p2019.2,
             family = quasipoisson)
summary(qpois5)
anova(qpois2, qpois5, test = "Chisq")

# See if I can improve model by transforming predictors
# Visualize RUCA. Versions with secondary codes (Prscrbr_RUCA), and without
# secondary codes (primary_RUCA) are nearly identical. Both figures suggest
# model could be improved by adding a squared term for RUCA.
p2019.2 %>%
    ggplot(aes(x = Prscrbr_RUCA, y = Antbtc_Tot_Clms)) +
    geom_smooth(method = "loess", span = 4)
p2019.2 %>%
    ggplot(aes(x = primary_RUCA, y = Antbtc_Tot_Clms)) +
    geom_smooth(method = "loess", span = 4)
p2019.2 %>%
    ggplot(aes(x = factor(primary_RUCA), y = Antbtc_Tot_Clms)) +
    stat_summary(geom = "pointrange")
p2019.2 %>%
    ggplot(aes(x = factor(rural), y = Antbtc_Tot_Clms)) +
    geom_boxplot()

# Model fit is statistically better with squared Prscrbr_RUCA
qpois6 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois6)
anova(qpois2, qpois6, test = "Chisq")

# Visualize claims ~ risk score. Weird nonlinearity. Suggests trying at least a squared term
p2019.2 %>%
    ggplot(aes(x = Bene_Avg_Risk_Scre, y = Antbtc_Tot_Clms)) +
    geom_smooth()

# Model fit is statistically the same with squared risk score
qpois7 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois7)
anova(qpois6, qpois7, test = "Chisq")

# Model fit is statistically better with squared and cubed risk score versus
# only linear risk score.
qpois8 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois8)
anova(qpois6, qpois8, test = "Chisq")

# Visualize claims ~ percent fem. Generally as the percentage of female beneficiaires gets higher, claims gets lower. Suggests a squared term might help.
p2019.2 %>%
    ggplot(aes(x = percent_fem, y = Antbtc_Tot_Clms)) +
    geom_smooth()

# Model fit is statistically better with squared percent female.
# *** Best model so far ***
qpois9 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9)
anova(qpois8, qpois9, test = "Chisq")
p2019.2$pred_qpois9 <- fitted(qpois9)

# Visualize claims ~ percent white. Shows some weird nonlinearities
p2019.2 %>%
    ggplot(aes(x = percent_white, y = Antbtc_Tot_Clms)) +
    geom_smooth(method = "lm")

# Model fit is statistically the same with percent white squared
qpois10 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white +
                        I(percent_white^2),
             data = p2019.2,
             family = quasipoisson)
summary(qpois10)
anova(qpois9, qpois10, test = "Chisq")

# Model fit is statistically the same for squared and cubed percent white versus linear only.
qpois11 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white +
                        I(percent_white^2) +
                        I(percent_white^3),
             data = p2019.2,
             family = quasipoisson)
summary(qpois11)
anova(qpois9, qpois11, test = "Chisq")

# Visualize claims densities for empirical verus qpois1 versus qpois9. qpois 1
# and 9 are very similar.
p2019.2 %>%
    dplyr::select(empirical = Antbtc_Tot_Clms, matches("^pred_")) %>%
    pivot_longer(cols = matches("empirical|^pred_"), names_to = "source",
                 values_to = "tot_clms") %>%
    filter(source %in% c("empirical", "pred_qpois0", "pred_qpois9")) %>%
    ggplot(aes(x = tot_clms, color = source)) +
    geom_density()

# R-squared for qpois0 versus qpois9. Shows ~ 7% gain from 0 to 9
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois0)^2
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9)^2

# Fit a negative binomial equivalent to qpois9 and check r-squared. Shows r2 = 0.36, lower than r2 = 0.39 for qpois9.
nb9 <- glm.nb(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)
summary(nb9)
p2019.2$pred_nb9 <- fitted(nb9)
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_nb9)^2

# Version of qpois9 where secondary RUCA codes are dropped
qpois9.1 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9.1)
p2019.2$pred_qpois9.1 <- fitted(qpois9.1)

# Version without secondary RUCA codes has r-squared of 0.3852--slightly lower
# than the version with secondary rUCA codes--0.3853. So I think we simplify by
# using only the primary codes in primary_RUCA (qpois9.1).
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9.1)^2

# Version of qpois9 where dummy rural is used. This won't be able to capture the
# curvilinear relationship between RUCA and claims, so probably won't fit as
# well.
qpois9.2 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        rural + 
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9.2)
p2019.2$pred_qpois9.2 <- fitted(qpois9.2)

# As expected, r-squared is slightly lower for a version of model 9 with rural versus primary_RUCA. 
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9.2)^2

# Version of qpois9 with RUCA as ordered factor. Coefficient names for ord_RUCA
# don't display correctly when it's an ordered factor. But fine when not
# ordered.
qpois9.3 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        ord_RUCA + 
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9.3)
p2019.2$pred_qpois9.3 <- fitted(qpois9.3)

# Slightly higher r-squared with factor RUCA, but only by 0.002
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9.3)^2
```

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Fit models
lm9 <- lm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)
lm9.1 <- lm(log_antbtc_clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)
qpois9 <- glm(
    Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
    # Antbtc_Tot_Clms ~ log(Tot_Benes) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
nb9 <- glm.nb(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)

# Extract fitted values & residuals. For GLM, use type = "pearson" to take into
# account increasing variance with increasing mean (see
# https://stats.stackexchange.com/questions/99052/residuals-in-poisson-regression)
p2019.2$pred_lm9 <- fitted(lm9)
p2019.2$resid_lm9 <- residuals(lm9)
p2019.2$pred_lm9.1 <- fitted(lm9.1)
p2019.2$resid_lm9.1 <- residuals(lm9.1)
p2019.2$pred_qpois9 <- fitted(qpois9)
p2019.2$resid_qpois9 <- residuals.glm(qpois9, type = "pearson")
p2019.2$pred_nb9 <- fitted(nb9)
p2019.2$resid_nb9 <- residuals.glm(nb9, type = "pearson")


```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.width = 10}

### Models of antibiotic claims for 2019

# Data:
# 
# - Number of rows in the 2019 by-providers dataset: `r format(nrow(p2019.0), big.mark = ",")`.
# - Number of rows with valid outcome values---i.e., values of Antbtc_Tot_Clms >= 11: `r format(nrow(p2019.1), big.mark = ",")`.
# - Proportion of rows with valid outcome values available for modeling after excluding NAs in predictors: `r format(round(nrow(p2019.2) / nrow(p2019.1), digits = 2), big.mark = ",")`.
# - Predictors included: Prscrbr_RUCA (rurality indicator with secondary codes dropped), Prscrbr_Gndr, Bene_Avg_Risk_Scre, Std_Provider_Type, percent_fem, percent_white.
# 
# These figures show r-squared for each model:


# Observed versus predicted for gaussian model
p2019.2 %>%
    ggplot(aes(x = Antbtc_Tot_Clms, y = pred_lm9)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    scale_x_continuous(limits = c(-50, 1000)) +
    scale_y_continuous(limits = c(-50, 1000)) +
    labs(title = "Observed versus predicted antibiotic claims from a gaussian model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_lm9)^2,
                   digits = 2)))

# Observed versus predicted for a gaussian model of log(Antbtc_Tot_Clms)
p2019.2 %>%
    ggplot(aes(x = log_antbtc_clms, y = pred_lm9.1)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    labs(title = "Observed versus predicted log(antibiotic claims) from a gaussian model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$log_antbtc_clms, p2019.2$pred_lm9.1)^2,
                   digits = 2)))

# Observed versus predicted for quasipoisson
p2019.2 %>%
    ggplot(aes(x = Antbtc_Tot_Clms, y = pred_qpois9)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    scale_x_continuous(limits = c(-50, 1000)) +
    scale_y_continuous(limits = c(-50, 1000)) +
    labs(title = "Observed versus predicted antibiotic claims from a quasipoisson model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9)^2,
                   digits = 2)))

# Observed versus predicted for negative binomial
p2019.2 %>%
    ggplot(aes(x = Antbtc_Tot_Clms, y = pred_nb9)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    scale_x_continuous(limits = c(-50, 1000)) +
    scale_y_continuous(limits = c(-50, 1000)) +
    labs(title = "Observed versus predicted antibiotic claims from a negative binomial model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_nb9)^2,
                   digits = 2)))

```

<br>

***

# General medicine

## Details

- All data in this section are from the [Medicare Part D Prescribers by Provider dataset](https://data.cms.gov/provider-summary-by-type-of-service/medicare-part-d-prescribers/medicare-part-d-prescribers-by-provider).
- The outcome variable, log(Claims/1K Beneficiaries), was modeled as normally-distributed. All values of Antbtc_Tot_Clms < 11 were excluded.
- Missing values of Tot_Benes were imputed as 10.
- All secondary codes were stripped from Prscrbr_RUCA--e.g., 4.1 became 4.

## Bivariate relationships

Data are general medicine providers in 2019. Each figure summarizes the relationship between a predictor and the outcome using a LOESS smoother.

### Prscrbr_RUCA

Treat RUCA as an ordered factor.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# General medicine for all years
gm <- p3 %>%
    filter(Prscrbr_Type_Std == "General Medicine")

# General medicine for 2019
gm2019 <- gm %>%
    filter(Year == 2019)

# RUCA doesn't look very continuous
# gm2019 %>%
#     ggplot(aes(x = Prscrbr_RUCA, y = log_claims_1k)) +
#     geom_jitter(alpha = 0.2, width = 0.2) +
#     geom_smooth() +
#     scale_x_continuous(breaks = seq(1, 10, 1))

gm2019 %>%
    ggplot(aes(x = Prscrbr_RUCA_fct, y = log_claims_1k)) +
    geom_boxplot()


```

<br>

***

### Prscrbr_Gndr

Treat provider gender as a factor.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# M > F
gm2019 %>%
    ggplot(aes(x = Prscrbr_Gndr, y = log_claims_1k)) +
    geom_boxplot()

```

<br>

***

### Bene_Avg_Risk_Scre

Suggests inclusion of squared and cubed HCC terms.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Suggests squared, cubed terms
gm2019 %>%
    ggplot(aes(x = Bene_Avg_Risk_Scre, y = log_claims_1k)) +
        geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

### Bene_Avg_Age

Suggests inclusion of a squared age term.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Suggests squared term
gm2019 %>%
    ggplot(aes(x = Bene_Avg_Age, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

### Bene_Prop_Fem

Suggests inclusion of squared and cubed proportion female terms.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Possible squared, cubed
gm2019 %>%
    ggplot(aes(x = Bene_Prop_Fem, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

### Bene_Prop_White

Suggests inclusion of squared and cubed proportion white terms.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Possible squared, cubed
gm2019 %>%
    ggplot(aes(x = Bene_Prop_White, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

## Model selection

The full model of claims_1k for the 2019 general medicine dataset is defined as a model that includes linear terms for all of the predictors in the preceding section, as well as squared and cubed terms if indicated.

The full model (called *m1*) is shown below.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

m1 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       I(Bene_Prop_Fem^3) +
       Bene_Prop_White +
       I(Bene_Prop_White^2) +
       I(Bene_Prop_White^3),
   data = gm2019)
summary(m1)

```

<br>

***

### Comparisons

Backward selection based on Chi-squared tests was used to arrive at a final model. We start by attempting to remove higher order cubed and squared terms. If a higher order term is shown to significantly contribute to the model fit, we keep it along with all lower order terms. For example, if Bene_Avg_Age^2 is found to contribute to the model fit, it is retained along with Bene_Avg_Age.

Comparison between the full model and one without Bene_Prop_White^3 (called *m2*) indicate that Bene_Prop_White^3 can be removed. *m2* becomes the new baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove of cubed percent white
m2 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       I(Bene_Prop_Fem^3) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = gm2019)
# summary(m2)

# Not statsig different, so remove cubed percent white
anova(m1, m2, test = "Chisq")

```

<br>

Comparison between *m2* and a model without Bene_Prop_Fem^3 (called *m3*) indicate that Bene_Prop_Fem^3 can be removed. *m3* becomes the new baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove cubed percent female
m3 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = gm2019)

# Not statsig different, so remove cubed percent female
anova(m2, m3, test = "Chisq")

```

<br>

Comparison between *m3* and a model without Bene_Avg_Risk_Scre^3 (called *m4*) indicate significantly better fit for *m3*. *m3* is retained as the baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove risk score cubed
m4 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = gm2019)

# Not statsig different, so remove cubed percent female
anova(m3, m4, test = "Chisq")

```

<br>

Comparison between *m3* and a model without without Bene_Prop_White^2 (called *m5*) indicate that Bene_Prop_White^2 can be removed. *m5* becomes the new baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove prop white squared
m5 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = gm2019)
# summary(m5)

# Not statsig different, so remove squared prop white
anova(m3, m5, test = "Chisq")

```

<br>

Comparison between *m5* and a model without Bene_Prop_Fem^2 (called *m6*) indicate significantly better fit for *m5*. *m5* is retained as the baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove prop female squared
m6 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       Bene_Prop_White,
   data = gm2019)

# Not statsig different, so remove squared prop white
anova(m5, m6, test = "Chisq")

```

<br>

Comparison between *m5* and a model without Bene_Avg_Age^2 (called *m7*) indicate significantly better fit for *m5*. *m5* is retained as the baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove age squared
m7 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = gm2019)

# Not statsig different, so remove squared prop white
anova(m5, m7, test = "Chisq")

```

<br>

***

### Final model

The final model (*m5*) is shown below. All higher order terms that did not improve model fit have been removed. All remaining terms except for Prscrbr_RUCA_fct8 are statistically significant.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

summary(m5)

```

<br>

***

## Fits by year

The final model specification was used to fit a series of models---one per year---to data from general medicine providers. Residuals plots and r-squared values for each model are provided below. Residuals for each year appear to be randomly distributed. R-squared values range from 0.14 to 0.20.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Models of general medicine data by year
years <- gm %>%
    count(Year) %>%
    pull(Year)
by_year_gm <- map(years, function(year) {
    data <- gm %>%
        filter(Year == !!year)
    year <- unique(data$Year)
    type <- unique(data$Prscrbr_Type_Std)
    fit <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       I(Prscrbr_RUCA^2) +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
       data = data)
    observed <- data$log_claims_1k
    fitted <- fitted(fit)
    max_axis <- max(c(observed, fitted))
    min_axis <- min(c(observed, fitted))
    residual <-  residuals(fit)
    rsq <- round(summary(fit)$r.squared, digits = 2)
    resid_plot <- tibble(fitted = fitted, residual = residual) %>%
        ggplot(aes(x = fitted, y = residual)) +
        geom_point(alpha = 0.2) +
        labs(title = paste(year, type),
             subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
             x = "Fitted log(Claims per 1K Beneficiaries)",
             y = "Residual\nlog(Claims\nper 1K Beneficiaries)")
    # fit_plot <- tibble(observed = observed, fitted = fitted) %>%
    #     ggplot(aes(x = fitted, y = observed)) +
    #     geom_point(alpha = 0.2) +
    #     geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    #     scale_x_continuous(limits = c(min_axis, max_axis)) +
    #     scale_y_continuous(limits = c(min_axis, max_axis)) +
    #     labs(title = paste(year, type),
    #          subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
    #          x = "Fitted log(Claims/1K Beneficiaries)",
    #          y = "Observed\nlog(Claims/1K Beneficiaries)")
    # fit_list = list(resid = resid_plot, fit = fit_plot)
    # fit_list
    resid_plot
})
names(by_year_gm) <- years
by_year_gm

```

## Coefficients by year

The figure below indicates that coefficients for models fit to general medicine data are relatively stable across years.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 10}

# Next question is how stable these coefficients are across years. Actually pretty stable, suggesting that we're looking at similar effects across all years in the dataset.
by_year_gm_coef <- map_dfr(years, function(year) {
    data <- gm %>%
        filter(Year == !!year)
    year <- unique(data$Year)
    type <- unique(data$Prscrbr_Type_Std)
    message(paste0("Fitting ", year))
    lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       I(Prscrbr_RUCA^2) +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
       data = data) %>%
        tidy() %>%
        mutate(year = !!year)
})

# Figure
by_year_gm_coef %>%
    filter(term != "(Intercept)") %>%
    ggplot(aes(x = year, y = estimate, group = term, color = term,
               fill = term)) +
    geom_line() +
    geom_ribbon(aes(ymin = estimate - std.error, ymax = estimate + std.error),
                alpha = 0.2, linetype = 0) +
    scale_x_continuous(breaks = seq(2013, 2019, 2)) +
    scale_color_discrete(guide = "none") +
    scale_fill_discrete(guide = "none") +
    facet_wrap(~ term) +
    labs(x = "Year", y = "Estimate")


# Next: Do plots showing residuals across years
# Do a section for linear predictors only. First establish that the more complex model is justified according to model comparisons. But give the option of looking at models with only linear predictors.

```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

## 2019 fits by provider type

# 2019 dataset
p2019 <- p3 %>%
    filter(Year == 2019) 

# 2019 provider types with at leaset 100 rows
provider_types <- p2019 %>%
    count(Prscrbr_Type_Std) %>%
    arrange(desc(n)) %>%
    filter(row_number() %in% 1:7) %>%
    pull(Prscrbr_Type_Std)

# Models of 2019 data by provider type
by_type_2019 <- map(provider_types, function(type) {
    data <- p2019 %>%
        filter(Prscrbr_Type_Std == type)
    year <- unique(data$Year)
    fit <- lm(
        log(Antbtc_Tot_Clms) ~ 1 +
            log(Tot_Benes) +
            Prscrbr_RUCA +
            Prscrbr_Gndr +
            Bene_Avg_Risk_Scre +
            Bene_Prop_Fem +
            Bene_Prop_White,
        data = data)
    observed <- log(data$Antbtc_Tot_Clms)
    fitted <- fitted(fit)
    max_axis <- max(c(observed, fitted))
    min_axis <- min(c(observed, fitted))
    residual <-  residuals(fit)
    rsq <- round(summary(fit)$r.squared, digits = 2)
    resid_plot <- tibble(fitted = fitted, residual = residual) %>%
        ggplot(aes(x = fitted, y = residual)) +
        geom_point(alpha = 0.2) +
        labs(title = paste(year, type),
             subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
             x = "Fitted log(Antbtc_Tot_Clms)",
             y = "Residual\nlog(Antbtc_Tot_Clms)")
    fit_plot <- tibble(observed = observed, fitted = fitted) %>%
        ggplot(aes(x = fitted, y = observed)) +
        geom_point(alpha = 0.2) +
        geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
        scale_x_continuous(limits = c(min_axis, max_axis)) +
        scale_y_continuous(limits = c(min_axis, max_axis)) +
        labs(title = paste(year, type),
             subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
             x = "Fitted log(Antbtc_Tot_Clms)",
             y = "Observed\nlog(Antbtc_Tot_Clms)")
    fit_list = list(resid = resid_plot, fit = fit_plot)
    fit_list
})
names(by_type_2019) <- provider_types
by_type_2019

```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

## General medicine coefficients for 2019

# 2019 general medicine data
gm2019 <- gm %>%
    filter(Year == 2019)

# Table of model coefficients
lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       I(Prscrbr_RUCA^2) +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
       data = gm2019) %>%
    tidy() %>%
    mutate(across(matches("estimate|error|statistic|value"),
                  ~ format(., digits = 2, scientific = TRUE))) %>%
    datatable(rownames = FALSE,
              options = list(dom = "t",
                             pageLength = ncol(gm2019)))


# Much less good at predicting claims 1k versus just claims. Probably because now we essentially have to predict two different outcomes: claims and beneficiaries.
m1 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       Bene_Prop_White,
   data = gm2019)
# summary(m1)

# Full model, based on what we saw in univarite plots

```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.height = 8, fig.width = 8}

# <br>
# 
# ***
# 
# ## 2019 coefficients by provider type
# 
# Coefficients show some variability across provider types for models fit to 2019 data.

# Table of coefficients
by_type_2019_coef <- map_dfr(provider_types, function(type) {
    data <- p2019 %>%
        filter(Prscrbr_Type_Std == !!type)
    year <- unique(data$year)
    type <- unique(data$Prscrbr_Type_Std)
    lm(log(Antbtc_Tot_Clms) ~ 1 +
            log(Tot_Benes) +
            Prscrbr_RUCA +
            Prscrbr_Gndr +
            Bene_Avg_Risk_Scre +
            Bene_Prop_Fem +
            Bene_Prop_White,
        data = data) %>%
        tidy() %>%
        mutate(Prscrbr_Type_Std = !!type)
})

# Figure
by_type_2019_coef %>%
    ggplot(aes(x = Prscrbr_Type_Std, y = estimate, group = term,
               color = term, fill = term)) +
    geom_line() +
    geom_ribbon(aes(ymin = estimate - std.error, ymax = estimate + std.error),
                alpha = 0.2, linetype = 0) +
    labs(x = "Provider\nType", y = "Estimate") +
    coord_flip() +
    scale_color_discrete(guide = "none") +
    scale_fill_discrete(guide = "none") +
    facet_wrap(~ term)
    

```

<br>

***

## Maps

### Observed

This map shows county-related differences in anbitiotic prescribing rates. Lighter colors represent higher prescribing rates (claims per 1K beneficiaries).

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

fit_gm_year <- map_dfr(years, function(year) {
    data <- gm %>%
        filter(Year == !!year,
               Prscrbr_County != "Not ID")
    fit <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = data)
    data %>%
        mutate(fitted_log_claims_1k = fitted(fit),
               fitted_claims_1k = exp(fitted_log_claims_1k))
})

# Compute O/E by year and county. 39 counties represented.
county_yr_oe <- fit_gm_year %>%
    filter(Prscrbr_County != "Not ID") %>%
    mutate(oe = claims_1k / fitted_claims_1k) %>%
    group_by(Year, Prscrbr_County) %>%
    summarize(n_oe = sum(!is.na(oe)),
              mean_oe = mean(oe, na.rm = TRUE),
              n_o = sum(!is.na(claims_1k)),
              mean_o = mean(claims_1k, na.rm = TRUE), .groups = "drop")

# Get county shapes and join in OEs. This data structure can have NAs in the mean column, but if there are NAs in any other columns it will cause the county to not be plotted, rather than being plotted gray (no data).
counties_sf <- counties(state = "ID", cb = FALSE) %>%
    left_join(county_yr_oe %>%
                  filter(Year == 2019) %>%
                  select(NAMELSAD = Prscrbr_County, n_oe, mean_oe, n_o, mean_o),
              by = "NAMELSAD") %>%
    mutate(n_oe = if_else(is.na(n_oe), 0L, n_oe),
           n_o = if_else(is.na(n_o), 0L, n_o),
           County = NAME)

# US county shapes
counties <- rjson::fromJSON(file = "https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json")

# US county FIPS
df <- read.csv(
    "https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv",
    colClasses = c(fips = "character")) %>%
    as_tibble() %>%
    select(fips)

df2 <- tibble(fips = counties_sf$COUNTYFP,
              state = counties_sf$STATEFP,
              county = counties_sf$NAME,
              mean = counties_sf$mean_o,
              N = counties_sf$n_o) %>%
    mutate(fips = paste0(state, fips)) %>%
    select(fips, county, state, mean, N)

# Join Idaho-specific info to df--the table with all US county FIPS
df3 <- df %>%
    left_join(df2, by = "fips") %>%
    mutate(hover_text = paste0(
        county, "<br>",
        "N = ", N, "<br>",
        "Claims/1K  = ", round(mean, digits = 2)),
        NA_trace = if_else(is.na(mean) & state == "16", 1L, NA_integer_))

# Figure
plot_ly() %>%
    
    # Trace for counties with defined O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$mean,
        zmin = min(df3$mean),
        zmax = max(df3$mean),
        text = df3$hover_text,
        hoverinfo = "text",
        colorscale = "Viridis",
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    
    # Trace for counties with NA O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$NA_trace,
        text = df3$hover_text,
        hoverinfo = "text",
        
        # Counties with missing values will be gray, but scale won't be shown
        colorscale = "Greys",
        showscale = FALSE,
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    colorbar(title = "Observed\nClaims per 1K\nBeneficiaries",
             outlinewidth = 0,
             thickness = 30) %>%
    plotly::layout(mapbox = list(
        style = "carto-positron",
        zoom = 4.6,
        center = list(lon = -114, lat = 45.6)))

```

<br>

***

### Observed/ Expected

This map shows county-related differences in antibiotic prescribing rates after controlling for provider gender and rurality, and beneficiary age, health status, proportion female, and proportion white.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Read in address info
# address_county <- read_feather("Address-query-county bank.feather")

# Loop over general medicine to fit models by year

# Table of Idaho county FIPS, county names, log(O/E).
# NOTE: Better if I get this info from counties JSON. Then I don't need to use
# tigris at all.
df2 <- tibble(fips = counties_sf$COUNTYFP,
              state = counties_sf$STATEFP,
              county = counties_sf$NAME,
              mean = counties_sf$mean_oe,
              N = counties_sf$n_oe) %>%
    mutate(fips = paste0(state, fips)) %>%
    select(fips, county, state, mean, N)

# Join Idaho-specific info to df--the table with all US county FIPS
df3 <- df %>%
    left_join(df2, by = "fips") %>%
    mutate(hover_text = paste0(
        county, "<br>",
        "N = ", N, "<br>",
        "O/E Claims/1K = ", round(mean, digits = 2)),
        NA_trace = if_else(is.na(mean) & state == "16", 1L, NA_integer_))

# Figure
plot_ly() %>%
    
    # Trace for counties with defined O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$mean,
        zmin = min(df3$mean),
        zmax = max(df3$mean),
        text = df3$hover_text,
        hoverinfo = "text",
        colorscale = "Viridis",
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    
    # Trace for counties with NA O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$NA_trace,
        text = df3$hover_text,
        hoverinfo = "text",
        
        # Counties with missing values will be gray, but scale won't be shown
        colorscale = "Greys",
        showscale = FALSE,
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    colorbar(title = "Observed/Expected\nClaims per 1K\nBeneficiaries",
             outlinewidth = 0,
             thickness = 30) %>%
    plotly::layout(mapbox = list(
        style = "carto-positron",
        zoom = 4.6,
        center = list(lon = -114, lat = 45.6)))

```

# Emergency medicine

```{r, eval = TRUE, echo = TRUE, error = FALSE, message = FALSE, warning = FALSE}

# Place names based on Google API
places <- read_feather("Address-name bank.feather") %>%
    select(place = name, dataset_address)

# Emergency medicine providers, all years
em <- p3 %>%
    filter(Prscrbr_Type_Std == "Emergency Medicine")

# 2019 emergency medicine with place names joined in
em2019 <- em %>%
    filter(Year == 2019) %>%
    left_join(places, by = "dataset_address")
    
# Counts of emergency medicine places
em2019 %>%
    count(place) %>%
    arrange(desc(n))

# Add categorization of places. This is just a partial coding of the places that
# occur more often. Could do more.
em2019 <- em2019 %>%
    mutate(org = case_when(
        str_detect(place, "Luke") ~ "St. Luke's",
        str_detect(place, "Alphonsus") ~ "St. Alphonsus",
        str_detect(place, "Portneuf") ~ "Portneuf",
        str_detect(place, "Kootenai") ~ "Kootenai",
        str_detect(place, "EIRMC") ~ "EIRMC",
        str_detect(place, "Joseph") ~ "St. Joseph",
        str_detect(place, "Madison") ~ "Madison Memorial Hospital",
        str_detect(place, "Bonner") ~ "Bonner General Health",
        str_detect(place, "Boundary") ~ "Boundary Community Hospital",
        str_detect(place, "Cassia") ~ "Cassia Regional Hospital",
        TRUE ~ "Other"))

# Orgs with >= 5 emergency medicine providers
orgs <- em2019 %>%
    count(org) %>%
    arrange(desc(n)) %>%
    filter(n >= 5,
           org != "Other") %>%
    pull(org)

# Counts for largest orgs. There are only seven with >= 5 providers.
em2019 %>%
    filter(org %in% orgs) %>%
    count(org) %>%
    arrange(desc(n))

# Visualize org diffs
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = org, y = log_claims_1k)) +
    geom_boxplot() +
    coord_flip()

# Simple model indicates that no levels or org are different than baseline
# (EIRMC).
em1 <- lm(
    log_claims_1k ~ 1 +
        org,
    data = em2019 %>%
        filter(org %in% orgs))
summary(em1)

# Look at bivariate relationships
# RUCA
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Prscrbr_RUCA_fct, y = log_claims_1k)) +
    geom_boxplot()

# Provider gender
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Prscrbr_Gndr, y = log_claims_1k)) +
    geom_boxplot()

# Bene HCC. Maybe squared and cubed terms
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Avg_Risk_Scre, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Bene age. Maybe squared and cubed terms
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Avg_Age, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Bene prop female. Squared term
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Prop_Fem, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Bene prop white. Squared term
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Prop_White, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Full model
em1 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       I(Bene_Avg_Age^3) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = em2019 %>%
       filter(org %in% orgs))
summary(em1)

# Evidence to drop cubed age
em2 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em1, em2, test = "Chisq")

# Evidence to retain cubed HCC
em3 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em2, em3, test = "Chisq")

# Evidence to drop white squared
em4 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em2, em4, test = "Chisq")

# Evidence to retain female squared
em5 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em4, em5, test = "Chisq")

# Evidence to drop squared age
em6 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em4, em6, test = "Chisq")

# Evidence to drop provider gender
em7 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em6, em7, test = "Chisq")

# Evidence to drop org
em8 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em7, em8, test = "Chisq")

# Evidence to drop RUCA
em9 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em8, em9, test = "Chisq")

# Evidence to drop age
em10 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em9, em10, test = "Chisq")

# Evidenc to drop white
em11 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em10, em11, test = "Chisq")

# Check cubed HCC again. Evidence still indicates it should be kept.
em12 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em11, em12, test = "Chisq")

# Check squared fem again. Evidence still indicates it should be kept.
em13 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       Bene_Prop_Fem,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em11, em13, test = "Chisq")

# Final model
summary(em11)

# Check residuals. Look okay
tibble(fitted = fitted(em11),
       residual = residuals(em11)) %>%
    ggplot(aes (x = fitted, y = residual)) +
    geom_point(alpha = 0.25)

# Note that even though we dropped org from the final model it could still be
# that orgs (e.g., St. Luke's versus St. Al's) matter in interaction with other
# predictors.

```

