---
title: "Idaho antibiotic use"
author:
    - Jeremy Boyd, Ph.D.
    - jeremyboyd@pm.me
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
    html_document:
        theme: spacelab
        toc: true
        toc_float: true
---

```{r setup, include = FALSE}

# Make default image type SVG
knitr::opts_chunk$set(dev = "svg")

```

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

###############################################################################
#### Read in by-provider ####
###############################################################################

# Read in provider type bank
p_types <- read_feather("Idaho provider type bank.feather") %>%
    select(Prscrbr_Type, Std_Provider_Type)

# Read in address-county info
address_county <- read_feather("Address-query-county bank.feather")

# By-provider dataset
p <- read_feather("Idaho prescribers by provider data.feather") %>%
    rename(Year = year) %>%
    mutate(Prscrbr_RUCA = floor(Prscrbr_RUCA),
           Prscrbr_RUCA_fct = factor(Prscrbr_RUCA),
           Prscrbr_Fem = if_else(Prscrbr_Gndr == "F", 1L, 0L),
           Bene_Prop_Fem = Bene_Feml_Cnt / Tot_Benes,
           Bene_Prop_White = Bene_Race_Wht_Cnt / Tot_Benes,
           dataset_address = str_squish(
                paste(Prscrbr_St1,
                      Prscrbr_St2,
                      Prscrbr_City,
                      Prscrbr_State_Abrvtn,
                      Prscrbr_Zip5)),
           claims_1k = Antbtc_Tot_Clms / (Tot_Benes / 1000),
           log_claims_1k = log(claims_1k)) %>%
    
    # Standardized prescriber types
    left_join(p_types, by = c("Prscrbr_Type")) %>%
    
    # County info
    left_join(address_county %>%
                  select(dataset_address, county),
              by = "dataset_address")

###############################################################################
#### Read in by-provider-and-drug ####
###############################################################################

# Names and class coding of generic drugs
generics <- read_feather("Generic drug bank.feather")

# Names of drug classes
drug_classes <- names(generics)[2:length(names(generics))]

# Read in by-provider-and-drug dataset
pd <- read_feather("Idaho prescribers by provider & drug data.feather") %>%
    
    # Join in coding for drug classes from generics
    left_join(generics, by = "Gnrc_Name") %>%
    select(Prscrbr_NPI, Year = year, Gnrc_Name, Tot_Clms, Antibiotic:Other)

# Summarize total claims per provider per year per drug class
pd2 <- map_dfr(drug_classes, function(class) {
    message(paste0("Getting claim data for class ", class, "..."))
    pd %>%
        filter(!!sym(class) == 1) %>%
        group_by(Prscrbr_NPI, Year) %>%
        summarize(
            n_drugs = sum(!is.na(Tot_Clms)),
            tot_clms = sum(Tot_Clms, na.rm = TRUE), .groups = "drop") %>%
        mutate(class = class) }) %>%
    
    # Join in Tot_Benes from p
    left_join(p %>%
                  select(Year , Prscrbr_NPI, Tot_Benes),
              by = c("Year", "Prscrbr_NPI")) %>%
    
    # Compute claims 1k
    mutate(claims_1k = tot_clms / (Tot_Benes / 1000),
           log_claims_1k = log(claims_1k))

```

<br>

***

# The by-provider dataset

The *Medicare Part D Prescribers - by Provider dataset* is publically-available [here](https://data.cms.gov/provider-summary-by-type-of-service/medicare-part-d-prescribers/medicare-part-d-prescribers-by-provider). Each row in the dataset gives prescribing information for a particular provider in a particular year. The present work focuses on rows representing Idaho providers in all available dataset years (currently `r min(p$Year)`-`r max(p$Year)`). This amounts to `r format(nrow(p), big.mark = ",")` rows.

The main focus of the study is on antibiotic prescribing behavior. Consequently, we are interested in the number of antibiotic claims providers have, and on variables that may be useful in predicting antibiotic claims. A subset of rows illustrating these data are shown below in Table 1.

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# By-provider example rows
p %>%
    select(Year, Prscrbr_NPI, Antbtc_Tot_Clms, Tot_Benes) %>%
    filter(Prscrbr_NPI == "1295735769",
           Year %in% c(2019, 2018)) %>%
    mutate(across(where(is.numeric), ~ round(., digits = 2))) %>%
    datatable(caption = "Table 1: Example rows from the by-providers dataset.",
              rownames = FALSE,
              options = list(dom = "t"))

# By-provider-and-drug example rows
pd2 %>%
    select(Year, Prscrbr_NPI, Drug = class, Tot_Clms = tot_clms) %>%
    filter(Prscrbr_NPI == "1295735769",
           Year %in% c(2019, 2018),
           !Drug %in% c("Antibiotic", "Macrolide")) %>%
    arrange(desc(Year)) %>%
    datatable(caption = "Table 1: Example rows from the by-providers dataset.",
              rownames = FALSE,
              options = list(dom = "t"))

```

The main outcome of interest is the number of claims per 1K beneficiaries. This requires the presence of valid values for both Antbtc_Tot_Clms and Tot_Benes, which means that significant amounts of data must be excluded.

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Table with missingness for claims and beneficiaries
p %>%
    select(Antbtc_Tot_Clms, Tot_Benes) %>%
    summarize(across(everything(), ~ sum(is.na(.) | . < 11))) %>%
    pivot_longer(cols = everything(), names_to = "column",
                 values_to = "n_missing") %>%
    mutate(pct_missing = format(n_missing / nrow(p) * 100, digits = 2,
                                nsmall = 2),
           n_missing = format(n_missing, big.mark = ",")) %>%
    arrange(desc(pct_missing)) %>%
    datatable(caption = "Table 1: Proportion of data with claim or beneficiary values that are missing or less than eleven",
              rownames = FALSE,
              colnames = c("Variable", "N", "%"),
              options = list(dom = "t",
                             pageLength = ncol(p)))

# Limit to rows with > 10 antibiotic claims and beneficiaries
p2 <- p %>%
    filter(!is.na(Antbtc_Tot_Clms),
           Antbtc_Tot_Clms > 10,
           !is.na(Tot_Benes))

```

In the remaining data, additional exclusions were enforced for variables with less than 10% missingness. Variables with missingness greather than or equal to 10% were not used in any analyses.

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Table showing no missing values in the columns we'll be using
p2 %>%
    summarize(across(everything(), ~ sum(is.na(.)))) %>%
    pivot_longer(cols = everything(), names_to = "column",
                 values_to = "n_missing") %>%
    filter(column %in% c("Prscrbr_Gndr", "Std_Provider_Type",
                         "Antbtc_Tot_Clms", "Tot_Benes", "Bene_Avg_Age",
                         "Bene_Avg_Risk_Scre", "Year", "Prscrbr_RUCA",
                         "Bene_Race_Wht_Cnt", "Bene_Feml_Cnt", "Bene_Dual_Cnt",
                         "Bene_Race_Natind_Cnt", "Bene_Race_Black_Cnt",
                         "Bene_Race_Api_Cnt", "Bene_Race_Hspnc_Cnt",
                         "Bene_Race_Othr_Cnt")) %>%
    mutate(pct_missing = format(n_missing / nrow(p2) * 100, digits = 2,
                                nsmall = 2),
           n_missing = format(n_missing, big.mark = ",")) %>%
    arrange(desc(pct_missing)) %>%
    datatable(caption = "Table 2: Missing values after exclusions based on claims and beneficiaries",
              rownames = FALSE,
              colnames = c("Variable", "N Missing", "% Missing"),
              options = list(dom = "t",
                             pageLength = ncol(p2)))

# Exclude missing values of Bene_Prop_Fem, Bene_Prop_White, Prscrbr_RUCA
p3 <- p2 %>%
    filter(!is.na(Bene_Prop_Fem),
           !is.na(Bene_Prop_White),
           !is.na(Prscrbr_RUCA)) %>%
    select(Year,
           Prscrbr_NPI,
           Prscrbr_Last_Org_Name,
           Prscrbr_First_Name,
           Prscrbr_Type_Std = Std_Provider_Type,
           Prscrbr_RUCA,
           Prscrbr_RUCA_fct,
           Prscrbr_Gndr,
           Prscrbr_Fem,
           Prscrbr_State_Abrvtn,
           Prscrbr_County = county,
           Antbtc_Tot_Clms,
           Tot_Benes,
           Bene_Avg_Age,
           Bene_Avg_Risk_Scre,
           Bene_Feml_Cnt,
           Bene_Prop_Fem,
           Bene_Prop_White,
           Bene_Race_Wht_Cnt,
           claims_1k,
           log_claims_1k,
           dataset_address)

```

<br>

***

## Descriptive statistics

### Providers by year

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Provider table by year
p3 %>%
    compute_sum_p(group = "Year") %>%
    provider_table()

```

<br>

***

### 2019 providers by type

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Provider table by year
p3 %>%
    filter(Year == 2019) %>%
    rename(`Provider Type` = Prscrbr_Type_Std) %>%
    compute_sum_p(group = "Provider Type") %>%
    provider_table()

```

<br>

***

### Beneficiaries by year

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Beneficiary table by year
p3 %>%
    compute_sum_p(group = "Year") %>%
    beneficiary_table()

```

<br>

***

### 2019 beneficiaries by provider type

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# 2019 beneficiaries by provider type
p3 %>%
    filter(Year == 2019) %>%
    rename(`Provider Type` = Prscrbr_Type_Std) %>%
    compute_sum_p(group = "Provider Type") %>%
    beneficiary_table()

```

<br>

***

### Antibiotic use by year

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Antibiotic use by year
p3 %>%
    compute_sum_p(group = "Year") %>%
    use_table()

```

<br>

***

### 2019 antibiotic use by provider type

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Antibiotic use by year
p3 %>%
    filter(Year == 2019) %>%
    rename(`Provider Type` = Prscrbr_Type_Std) %>%
    compute_sum_p(group = "Provider Type") %>%
    use_table()

```

# The by-provider-and-drug dataset

The figures below show average claims per 1K beneficiaries for different drug classes over time.

- Lines represent unweighted means.
- Ribbons are bootstrapped 95% CIs of the means.
- Percentages show the mean annual percent change. For example, if a facet shows -1% that means that use of the drug declined by 1% on average per year.
- Trends that are significant show a *p*-value.
- *P*-values were generated from models of log(claims 1k) ~ year for each drug class.

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.heigh = 4, fig.width = 11}


# Examples showing what data looks like
pd2 %>%
    filter(Prscrbr_NPI == "1003012204",
           Year == 2019)
pd2 %>%
    filter(Prscrbr_NPI == "1003012204",
           Year == 2014)

# Compute average percent change across years for each class
pct_change <- pd2 %>%
    group_by(class, Year) %>%
    summarize(n_prscrbr = sum(!is.na(claims_1k)),
              mean_clms_1k = mean(claims_1k, na.rm = TRUE),
              .groups = "drop") %>%
    pivot_wider(matches("class"), names_from = "Year",
                values_from = "mean_clms_1k") %>%
    mutate(change13_14 = (`2014` - `2013`) / `2013` * 100,
           change14_15 = (`2015` - `2014`) / `2014` * 100,
           change15_16 = (`2016` - `2015`) / `2015` * 100,
           change16_17 = (`2017` - `2016`) / `2016` * 100,
           change17_18 = (`2018` - `2017`) / `2017` * 100,
           change18_19 = (`2019` - `2018`) / `2018` * 100) %>%
    select(-(`2013`:`2019`)) %>%
    pivot_longer(matches("change"), names_to = "years",
                 values_to = "pct_change") %>%
    group_by(class) %>%
    summarize(n = sum(!is.na(pct_change)),
              mean_pct_chg_yr = mean(pct_change, na.rm = TRUE),
              .groups = "drop") %>%
    arrange(mean_pct_chg_yr)

# Compute year effects for each class
year_effects <- map_dfr(drug_classes, function(class) {
    data <- pd2 %>% filter(class == !!class)
    lm(log_claims_1k ~ Year,
       data = data) %>%
    tidy() %>%
    mutate(class = !!class) }) %>%
    filter(term == "Year") %>%
    arrange(p.value)

# Compute mean claims 1k for each class
clms_1k_tab <- pd2 %>%
    group_by(class) %>%
    summarize(clms_1k = mean(claims_1k, na.rm = TRUE), .groups = "drop") %>%
    arrange(desc(clms_1k))

# Function to compute mean
mean_fun <- function(data, indices) {
    d <- data[indices]
    return(mean(d, na.rm = TRUE))
    }

# Cross years & classes
year_class <- expand_grid(year = unique(pd2$Year),
                          class = drug_classes)

# Compute bootstrapped 95% CI for mean(claims_1k) for each combination of year
# and class.
year_class_ci <- map2_dfr(year_class$class, year_class$year,
                          function(class, year) {
    data <- pd2 %>%
        filter(class == !!class,
               Year == !!year)
    reps <- boot(data$claims_1k, statistic = mean_fun, R = 1000)
    ci <- boot.ci(reps, conf = 0.95, type = "basic")
    tibble(class = !!class,
           Year = !!year,
           lower = ci$basic[4],
           upper = ci$basic[5])
})

# Figure
fig_data <- pd2 %>%
    group_by(class, Year) %>%
    summarize(mean = mean(claims_1k, na.rm = TRUE), .groups = "drop") %>%
    
    # Join in lower & upper CIs
    left_join(year_class_ci, by = c("Year", "class")) %>%
    
    # Join in percent change
    left_join(pct_change %>%
                  select(class, mean_pct_chg_yr), by = "class") %>%
    
    # Join in variable to sort levels of claims on
    left_join(clms_1k_tab, by = "class") %>%
    
    # Join in p-values
    left_join(year_effects %>%
                  select(class, p.value), by = "class") %>%
    
    mutate(p_label = if_else(p.value < 0.05,
                             paste0(
                                 "\n",
                                 format(p.value,
                                        scientific = TRUE,
                                        digits = 3)),
                             ""),
           facet_label = paste0(class, "\n",
                                round(mean_pct_chg_yr, digits = 2), "%",
                                p_label),
           
           # Order levels of facet_label
           facet_label = fct_reorder(facet_label, -clms_1k))

# Regexp to match five classes with highest claims 1k, excluding Other
first_five <- paste0(c(clms_1k_tab$class[1:4], clms_1k_tab$class[6]),
                     collapse = "|")

# Regexp to match five classes with lowest claims 1k
second_five <- paste0(clms_1k_tab$class[7:11], collapse = "|")

# First five
fig_data %>%
    filter(str_detect(facet_label, first_five)) %>%
    ggplot(aes(x = Year, y = mean, ymin = lower, ymax = upper,
               group = facet_label, color = facet_label, fill = facet_label)) +
    geom_ribbon(alpha = 0.2, linetype = 0) +
    geom_line() +
    scale_x_continuous(breaks = seq(2013, 2019, 2)) +
    scale_y_continuous(limits = c(0, 500)) +
    facet_wrap(~ facet_label, ncol = 5) +
    labs(x = "Year",
         y = "Claims/1K\nbeneficiaries",
         color = "Class") +
    theme(legend.position = "none")
ggsave("figures/Claims 1k by class by year top five.png", height = 4,
       width = 12)

# Second five
fig_data %>%
    filter(str_detect(facet_label, second_five)) %>%
    ggplot(aes(x = Year, y = mean, ymin = lower, ymax = upper,
               group = facet_label, color = facet_label, fill = facet_label)) +
    geom_ribbon(alpha = 0.2, linetype = 0) +
    geom_line() +
    scale_x_continuous(breaks = seq(2013, 2019, 2)) +
    scale_y_continuous(limits = c(0, 500)) +
    facet_wrap(~ facet_label, ncol = 5) +
    labs(x = "Year",
         y = "Claims\nper 1K\nbeneficiaries",
         color = "Class") +
    theme(legend.position = "none")
ggsave("figures/Claims 1k by class by year bottom five.png", height = 4,
       width = 12)

```

<br>

***

### Source of the numerator in claims / 1K beneficiaries

A recent report by Gouin and colleagues (2022) based on Medicare Part D data shows antibiotics claims of ~ 400 per 1K beneficiaries. In contrast, I'm seeing numbers closer to ~ 200 per 1K. Most of this seems to be related to the dataset that claims numbers are coming from. In Gouin et al. they're taking claims numbers from the by-provider dataset. In this dataset, each row represents a provider, and a column labeled Antbtc_Tot_Clms gives all of the antibiotic claims that provider has for the given year. In contrast, I'm taking claims numbers from the by-provider-and-drug dataset. For this dataset, each row gives info for a particular provider for a particular drug. We identify all of drugs that are antibiotics and add up the claims to get a total number of antibiotic claims a provider has in a given year.

Crucially for the by-provider-and-drug dataset, rows with < 11 claims are *not included*. This means that we're missing claims. This isn't as big an issue in the by-provider dataset because (1) the antibiotic count is aggregated across lots of different drugs, so the numbers are more often >= 11, and (2) even when the number is lower, rows with NA *are included*. This allows for imputation.

In the figure below I show that antibiotic claims per 1K beneficiaries is quite a bit lower when the numerator (the number of claims) comes from the by-provider-and-drug dataset (pd) versus the by-provider dataset (p).

This isn't necessarily a problem--just need to explain how we're computing the stat. The way we're doing it is giving us the ability to break out different kinds of antibiotics, but at the expense of missing rows, which means we're consistently underestimating.

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Comparison between x and y shows that mean claims / 1K is higher when computing with the number of antibiotic claims from the by-providers dataset (x) than the by-providers-and-drug dataset (y). This is probably why my numbers seem lower than what's reported in Gouin (2022). Find out how the Antbtc_Tot_Clms column is computed in the by-providers dataset. Want to try to approximate what it's doing as closely as possible when getting numerators from by-provider-and-drug. Also, are we correctly coding for all antibiotics in by-provider-and-drug? Looks like the number of prescribers and beneficiaries is the same across the two datasets, but the number of claims is quite a bit lower when we take it from provider-by-drug, leading to lower claims per 1k beneficiaries. Probably one thing that's going on is that we lose all rows in provider-by-drug that are < 11. So that pushes our claim counts lower. Not as much of an issue in by-provider because the antibiotic claim counts get aggregated to much larger numbers, so fewer < 11. And we can't impute in the pd table since the rows that would have NAs have been removed before we get to it.
p_vs_pd_num <- bind_rows(
    p %>%
        mutate(Tot_Benes = if_else(is.na(Tot_Benes), 10, Tot_Benes),
               numerator = "p") %>%
        group_by(year, numerator) %>%
        dplyr::summarize(
            n_prscrbr = sum(!is.na(Prscrbr_NPI)),
            n_benes = sum(Tot_Benes, na.rm = TRUE),
            n_claims = sum(Antbtc_Tot_Clms, na.rm = TRUE),
            mean_benes = mean(Tot_Benes, na.rm = TRUE),
            mean_claims = mean(Antbtc_Tot_Clms, na.rm = TRUE),
            mean_claims_1k = mean(Antbtc_Tot_Clms / (Tot_Benes / 1000),
                                  na.rm = TRUE),
            .groups = "drop"),
    p3 %>%
        filter(class == "Antibiotic") %>%
        mutate(Tot_Benes = if_else(is.na(Tot_Benes), 10, Tot_Benes),
               numerator = "pd") %>%
        group_by(year, numerator) %>%
        dplyr::summarize(
            n_prscrbr = sum(!is.na(Prscrbr_NPI)),
            n_benes = sum(Tot_Benes, na.rm = TRUE),
            n_claims = sum(tot_clms, na.rm = TRUE),
            mean_benes = mean(Tot_Benes, na.rm = TRUE),
            mean_claims = mean(tot_clms, na.rm = TRUE),
            mean_claims_1k = mean(tot_clms / (Tot_Benes / 1000),
                                  na.rm = TRUE),
            .groups = "drop"))

# Fewer claims when summarized from the by-provider-and-drug table versus the by-provider table.
p_vs_pd_num %>%
    ggplot(aes(
        x = year,
        y = mean_claims,
        group = numerator,
        color = numerator)) +
    geom_line()

# Mean number of beneficiaries. These are identical because we're always taking
# the number of beneficiaries from the by-provider table.
posd = position_dodge(0.4)
p_vs_pd_num %>%
    ggplot(aes(
        x = year,
        y = mean_benes,
        group = numerator,
        color = numerator)) +
    geom_line(position = posd) +
    labs(subtitle = str_wrap("Beneficiary numbers don't vary--always from the by-providers table", 40))

# Lower mean claims / 1k beneficiaries when claims come from the by-provider-and-drug table versus the by-provider table.
p_vs_pd_num %>%
    ggplot(aes(
        x = year,
        y = mean_claims_1k,
        group = numerator,
        color = numerator)) +
    geom_line()

```

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

### Comparison of weighted versus unweighted means

# Number of providers per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    ggplot(mapping = aes(x = year, y = n_prscrbr)) +
    geom_line()
               
# Mean beneficiaries by year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    ggplot(mapping = aes(x = year, y = mean_ben)) +
    geom_line() +
    geom_errorbar(aes(ymin = mean_ben - sd_ben,
                      ymax = mean_ben + sd_ben),
                  width = 0.2,
                  size = 0.5)

# Mean beneficiary age per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_age_wt, mean_age_unwt) %>%
    pivot_longer(cols = matches("mean_age"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean % female per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_fem_wt, mean_fem_unwt) %>%
    pivot_longer(cols = matches("mean_fem"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean hcc per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_hcc_wt, mean_hcc_unwt) %>%
    pivot_longer(cols = matches("mean_hcc"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean claims per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_claims_wt, mean_claims_unwt) %>%
    pivot_longer(cols = matches("mean_claims"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

# Mean claims per 1k beneficiaries per year
p3 %>%
    filter(class == "Antibiotic") %>%
    compute_summary_table(group = "year") %>%
    select(year, mean_claims_1k_wt, mean_claims_1k_unwt) %>%
    pivot_longer(cols = matches("mean_claims"), names_to = "type",
                 values_to = "mean") %>%
    ggplot(mapping = aes(x = year, y = mean, color = type, group = type)) +
    geom_line()

```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

### Can we get claims per 1k beneficiaries to look normal?

# Not really.
# 
# Logging gets us close to normal, but with 77% data loss.


# All of these distributions are entirely non-normal.
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = claims_1k)) +
    geom_density()

# Logging improves normality, but you lose massive amounts of data
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = log_claims_1k)) +
    geom_density()

# Amount of data you lose when trying to take log(0)
(p3 %>%
    filter(log_claims_1k == -Inf) %>%
    nrow()) / nrow(p3)

# Distribution of log(claims_1k + 1)
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = log_claims_1k_one)) +
    geom_density()

# Distribution of log(claims_1k + .5 * minimum nonzero claims_1k)
p3 %>%
    filter(class == "Antibiotic") %>%
    ggplot(aes(x = log_claims_1k_half_min)) +
    geom_density()

```

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Pairs plot
# library(GGally)
# p2019.2 %>%
#     select(Antbtc_Tot_Clms:Prscrbr_Gndr, Bene_Avg_Age, Bene_Avg_Risk_Scre,
#            Std_Provider_Type, percent_fem, percent_white) %>%
#     select(where(is.numeric)) %>%
#     ggpairs()
# 
# # Hurdle model
# mh1 <- pscl::hurdle(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
#                         Prscrbr_RUCA +
#                         Prscrbr_Gndr +
#                         Bene_Avg_Age +
#                         Bene_Avg_Risk_Scre +
#                         Std_Provider_Type +
#                         percent_fem +
#                         percent_white,
#              data = p2019.2,
#              dist = "negbin")
# summary(mh1)
# 
# 
# zinb1 <- pscl::zeroinfl(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
#                         Prscrbr_RUCA +
#                         Prscrbr_Gndr +
#                         Bene_Avg_Age +
#                         Bene_Avg_Risk_Scre +
#                         Std_Provider_Type +
#                         percent_fem +
#                         percent_white,
#              data = p2019.2,
#              dist = "negbin")
# summary(zinb1)

# Poisson
pois1 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Age +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = poisson)
summary(pois1)

# Intercept-only qpois model
qpois0 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1,
             data = p2019.2,
             family = quasipoisson)

# Quasi-poisson to get dispersion parameter. Indicates over-dispersion
qpois1 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Age +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois1)
anova(qpois1, test = "Chisq")

# Negative binomial
nb1 <- glm.nb(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Age +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2)
summary(nb1)

# Add fitted to visualize fit to empirical
p2019.2$pred_pois <- fitted(pois1)
p2019.2$pred_qpois0 <- fitted(qpois0)
p2019.2$pred_qpois1 <- fitted(qpois1)
p2019.2$pred_nb <- fitted(nb1)

# Visualize distribution of claims for empirical and models. Poisson is
# overplotted by quasipoisson--they have the same parameter values. But SEs are
# larger for quasi, which is supposed to be good, I think. Both quasipoisson and
# nb look like pretty good fits, with quasi maybe being a tad better. SEs larger for quasi versus nb. Significance is the same for quasi vs. nb. Parameter values are all similar.
p2019.2 %>%
    dplyr::select(empirical = Antbtc_Tot_Clms, matches("^pred_")) %>%
    pivot_longer(cols = matches("empirical|^pred_"), names_to = "source",
                 values_to = "tot_clms") %>%
    ggplot(aes(x = tot_clms, color = source)) +
    geom_density()

# Model fit isn't statistically different without age
qpois2 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois2)
anova(qpois1, qpois2, test = "Chisq")

# Model fit is statistically worse without risk score
qpois3 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
anova(qpois2, qpois3, test = "Chisq")

# Model fit is marginally worse (p = 0.12) without percent_fem
qpois4 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois4)
anova(qpois2, qpois4, test = "Chisq")

# Model fit is statistically worse without percent_white
qpois5 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem,
             data = p2019.2,
             family = quasipoisson)
summary(qpois5)
anova(qpois2, qpois5, test = "Chisq")

# See if I can improve model by transforming predictors
# Visualize RUCA. Versions with secondary codes (Prscrbr_RUCA), and without
# secondary codes (primary_RUCA) are nearly identical. Both figures suggest
# model could be improved by adding a squared term for RUCA.
p2019.2 %>%
    ggplot(aes(x = Prscrbr_RUCA, y = Antbtc_Tot_Clms)) +
    geom_smooth(method = "loess", span = 4)
p2019.2 %>%
    ggplot(aes(x = primary_RUCA, y = Antbtc_Tot_Clms)) +
    geom_smooth(method = "loess", span = 4)
p2019.2 %>%
    ggplot(aes(x = factor(primary_RUCA), y = Antbtc_Tot_Clms)) +
    stat_summary(geom = "pointrange")
p2019.2 %>%
    ggplot(aes(x = factor(rural), y = Antbtc_Tot_Clms)) +
    geom_boxplot()

# Model fit is statistically better with squared Prscrbr_RUCA
qpois6 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois6)
anova(qpois2, qpois6, test = "Chisq")

# Visualize claims ~ risk score. Weird nonlinearity. Suggests trying at least a squared term
p2019.2 %>%
    ggplot(aes(x = Bene_Avg_Risk_Scre, y = Antbtc_Tot_Clms)) +
    geom_smooth()

# Model fit is statistically the same with squared risk score
qpois7 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois7)
anova(qpois6, qpois7, test = "Chisq")

# Model fit is statistically better with squared and cubed risk score versus
# only linear risk score.
qpois8 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois8)
anova(qpois6, qpois8, test = "Chisq")

# Visualize claims ~ percent fem. Generally as the percentage of female beneficiaires gets higher, claims gets lower. Suggests a squared term might help.
p2019.2 %>%
    ggplot(aes(x = percent_fem, y = Antbtc_Tot_Clms)) +
    geom_smooth()

# Model fit is statistically better with squared percent female.
# *** Best model so far ***
qpois9 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9)
anova(qpois8, qpois9, test = "Chisq")
p2019.2$pred_qpois9 <- fitted(qpois9)

# Visualize claims ~ percent white. Shows some weird nonlinearities
p2019.2 %>%
    ggplot(aes(x = percent_white, y = Antbtc_Tot_Clms)) +
    geom_smooth(method = "lm")

# Model fit is statistically the same with percent white squared
qpois10 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white +
                        I(percent_white^2),
             data = p2019.2,
             family = quasipoisson)
summary(qpois10)
anova(qpois9, qpois10, test = "Chisq")

# Model fit is statistically the same for squared and cubed percent white versus linear only.
qpois11 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white +
                        I(percent_white^2) +
                        I(percent_white^3),
             data = p2019.2,
             family = quasipoisson)
summary(qpois11)
anova(qpois9, qpois11, test = "Chisq")

# Visualize claims densities for empirical verus qpois1 versus qpois9. qpois 1
# and 9 are very similar.
p2019.2 %>%
    dplyr::select(empirical = Antbtc_Tot_Clms, matches("^pred_")) %>%
    pivot_longer(cols = matches("empirical|^pred_"), names_to = "source",
                 values_to = "tot_clms") %>%
    filter(source %in% c("empirical", "pred_qpois0", "pred_qpois9")) %>%
    ggplot(aes(x = tot_clms, color = source)) +
    geom_density()

# R-squared for qpois0 versus qpois9. Shows ~ 7% gain from 0 to 9
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois0)^2
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9)^2

# Fit a negative binomial equivalent to qpois9 and check r-squared. Shows r2 = 0.36, lower than r2 = 0.39 for qpois9.
nb9 <- glm.nb(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        Prscrbr_RUCA +
                        I(Prscrbr_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)
summary(nb9)
p2019.2$pred_nb9 <- fitted(nb9)
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_nb9)^2

# Version of qpois9 where secondary RUCA codes are dropped
qpois9.1 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9.1)
p2019.2$pred_qpois9.1 <- fitted(qpois9.1)

# Version without secondary RUCA codes has r-squared of 0.3852--slightly lower
# than the version with secondary rUCA codes--0.3853. So I think we simplify by
# using only the primary codes in primary_RUCA (qpois9.1).
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9.1)^2

# Version of qpois9 where dummy rural is used. This won't be able to capture the
# curvilinear relationship between RUCA and claims, so probably won't fit as
# well.
qpois9.2 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        rural + 
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9.2)
p2019.2$pred_qpois9.2 <- fitted(qpois9.2)

# As expected, r-squared is slightly lower for a version of model 9 with rural versus primary_RUCA. 
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9.2)^2

# Version of qpois9 with RUCA as ordered factor. Coefficient names for ord_RUCA
# don't display correctly when it's an ordered factor. But fine when not
# ordered.
qpois9.3 <- glm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        ord_RUCA + 
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
summary(qpois9.3)
p2019.2$pred_qpois9.3 <- fitted(qpois9.3)

# Slightly higher r-squared with factor RUCA, but only by 0.002
cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9.3)^2
```

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Fit models
lm9 <- lm(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)
lm9.1 <- lm(log_antbtc_clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)
qpois9 <- glm(
    Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
    # Antbtc_Tot_Clms ~ log(Tot_Benes) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2,
             family = quasipoisson)
nb9 <- glm.nb(Antbtc_Tot_Clms ~ offset(log(Tot_Benes)) + 1 +
                        primary_RUCA +
                        I(primary_RUCA^2) +
                        Prscrbr_Gndr +
                        Bene_Avg_Risk_Scre +
                        I(Bene_Avg_Risk_Scre^2) +
                        I(Bene_Avg_Risk_Scre^3) +
                        Std_Provider_Type +
                        percent_fem +
                        I(percent_fem^2) +
                        percent_white,
             data = p2019.2)

# Extract fitted values & residuals. For GLM, use type = "pearson" to take into
# account increasing variance with increasing mean (see
# https://stats.stackexchange.com/questions/99052/residuals-in-poisson-regression)
p2019.2$pred_lm9 <- fitted(lm9)
p2019.2$resid_lm9 <- residuals(lm9)
p2019.2$pred_lm9.1 <- fitted(lm9.1)
p2019.2$resid_lm9.1 <- residuals(lm9.1)
p2019.2$pred_qpois9 <- fitted(qpois9)
p2019.2$resid_qpois9 <- residuals.glm(qpois9, type = "pearson")
p2019.2$pred_nb9 <- fitted(nb9)
p2019.2$resid_nb9 <- residuals.glm(nb9, type = "pearson")


```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.width = 10}

### Models of antibiotic claims for 2019

# Data:
# 
# - Number of rows in the 2019 by-providers dataset: `r format(nrow(p2019.0), big.mark = ",")`.
# - Number of rows with valid outcome values---i.e., values of Antbtc_Tot_Clms >= 11: `r format(nrow(p2019.1), big.mark = ",")`.
# - Proportion of rows with valid outcome values available for modeling after excluding NAs in predictors: `r format(round(nrow(p2019.2) / nrow(p2019.1), digits = 2), big.mark = ",")`.
# - Predictors included: Prscrbr_RUCA (rurality indicator with secondary codes dropped), Prscrbr_Gndr, Bene_Avg_Risk_Scre, Std_Provider_Type, percent_fem, percent_white.
# 
# These figures show r-squared for each model:


# Observed versus predicted for gaussian model
p2019.2 %>%
    ggplot(aes(x = Antbtc_Tot_Clms, y = pred_lm9)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    scale_x_continuous(limits = c(-50, 1000)) +
    scale_y_continuous(limits = c(-50, 1000)) +
    labs(title = "Observed versus predicted antibiotic claims from a gaussian model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_lm9)^2,
                   digits = 2)))

# Observed versus predicted for a gaussian model of log(Antbtc_Tot_Clms)
p2019.2 %>%
    ggplot(aes(x = log_antbtc_clms, y = pred_lm9.1)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    labs(title = "Observed versus predicted log(antibiotic claims) from a gaussian model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$log_antbtc_clms, p2019.2$pred_lm9.1)^2,
                   digits = 2)))

# Observed versus predicted for quasipoisson
p2019.2 %>%
    ggplot(aes(x = Antbtc_Tot_Clms, y = pred_qpois9)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    scale_x_continuous(limits = c(-50, 1000)) +
    scale_y_continuous(limits = c(-50, 1000)) +
    labs(title = "Observed versus predicted antibiotic claims from a quasipoisson model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_qpois9)^2,
                   digits = 2)))

# Observed versus predicted for negative binomial
p2019.2 %>%
    ggplot(aes(x = Antbtc_Tot_Clms, y = pred_nb9)) +
    geom_point(alpha = 0.1) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    scale_x_continuous(limits = c(-50, 1000)) +
    scale_y_continuous(limits = c(-50, 1000)) +
    labs(title = "Observed versus predicted antibiotic claims from a negative binomial model",
         subtitle = paste(
             "R-squared =",
             round(cor(p2019.2$Antbtc_Tot_Clms, p2019.2$pred_nb9)^2,
                   digits = 2)))

```

<br>

***

# General medicine

## Details

- All data in this section are from the [Medicare Part D Prescribers by Provider dataset](https://data.cms.gov/provider-summary-by-type-of-service/medicare-part-d-prescribers/medicare-part-d-prescribers-by-provider).
- Wows with fewer than 11 antibiotic claims or beneficiaries were excluded.
- The outcome variable, log(Claims/1K Beneficiaries), was modeled as normally-distributed.
- All secondary codes were stripped from Prscrbr_RUCA--e.g., 4.1 became 4.

## Bivariate relationships

Data are general medicine providers in 2019. Each figure summarizes the relationship between a predictor and the outcome using a LOESS smoother.

### Prscrbr_RUCA

Treat RUCA as an ordered factor.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# General medicine for all years
gm <- p3 %>%
    filter(Prscrbr_Type_Std == "General Medicine")

# General medicine for 2019
gm2019 <- gm %>%
    filter(Year == 2019)

# RUCA doesn't look very continuous
# gm2019 %>%
#     ggplot(aes(x = Prscrbr_RUCA, y = log_claims_1k)) +
#     geom_jitter(alpha = 0.2, width = 0.2) +
#     geom_smooth() +
#     scale_x_continuous(breaks = seq(1, 10, 1))

gm2019 %>%
    ggplot(aes(x = Prscrbr_RUCA_fct, y = log_claims_1k)) +
    geom_boxplot()


```

<br>

***

### Prscrbr_Gndr

Treat provider gender as a factor.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# M > F
gm2019 %>%
    ggplot(aes(x = Prscrbr_Gndr, y = log_claims_1k)) +
    geom_boxplot()

```

<br>

***

### Bene_Avg_Risk_Scre

Suggests inclusion of squared and cubed HCC terms.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Suggests squared, cubed terms
gm2019 %>%
    ggplot(aes(x = Bene_Avg_Risk_Scre, y = log_claims_1k)) +
        geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

### Bene_Avg_Age

Suggests inclusion of a squared age term.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Suggests squared term
gm2019 %>%
    ggplot(aes(x = Bene_Avg_Age, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

### Bene_Prop_Fem

Suggests inclusion of squared and cubed proportion female terms.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Possible squared, cubed
gm2019 %>%
    ggplot(aes(x = Bene_Prop_Fem, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

### Bene_Prop_White

Suggests inclusion of squared and cubed proportion white terms.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Possible squared, cubed
gm2019 %>%
    ggplot(aes(x = Bene_Prop_White, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

```

<br>

***

## Model selection

The full model of claims_1k for the 2019 general medicine dataset is defined as a model that includes linear terms for all of the predictors in the preceding section, as well as squared and cubed terms if indicated.

The full model (called *m1*) is shown below.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

m1 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       I(Bene_Prop_Fem^3) +
       Bene_Prop_White +
       I(Bene_Prop_White^2) +
       I(Bene_Prop_White^3),
   data = gm2019)
summary(m1)

```

<br>

***

### Comparisons

Backward selection based on Chi-squared tests was used to arrive at a final model. We start by attempting to remove higher order cubed and squared terms. If a higher order term is shown to significantly contribute to the model fit, we keep it along with all lower order terms. For example, if Bene_Avg_Age^2 is found to contribute to the model fit, it is retained along with Bene_Avg_Age.

Comparison between the full model and one without Bene_Prop_White^3 (called *m2*) indicate that Bene_Prop_White^3 can be removed. *m2* becomes the new baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove of cubed percent white
m2 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       I(Bene_Prop_Fem^3) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = gm2019)
# summary(m2)

# Not statsig different, so remove cubed percent white
anova(m1, m2, test = "Chisq")

```

<br>

Comparison between *m2* and a model without Bene_Prop_Fem^3 (called *m3*) indicate that Bene_Prop_Fem^3 can be removed. *m3* becomes the new baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove cubed percent female
m3 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = gm2019)

# Not statsig different, so remove cubed percent female
anova(m2, m3, test = "Chisq")

```

<br>

Comparison between *m3* and a model without Bene_Avg_Risk_Scre^3 (called *m4*) indicate significantly better fit for *m3*. *m3* is retained as the baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove risk score cubed
m4 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = gm2019)

# Not statsig different, so remove cubed percent female
anova(m3, m4, test = "Chisq")

```

<br>

Comparison between *m3* and a model without without Bene_Prop_White^2 (called *m5*) indicate that Bene_Prop_White^2 can be removed. *m5* becomes the new baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove prop white squared
m5 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = gm2019)
# summary(m5)

# Not statsig different, so remove squared prop white
anova(m3, m5, test = "Chisq")

```

<br>

Comparison between *m5* and a model without Bene_Prop_Fem^2 (called *m6*) indicate significantly better fit for *m5*. *m5* is retained as the baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove prop female squared
m6 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       Bene_Prop_White,
   data = gm2019)

# Statsig different, so retain Bene_Prop_Fem^2 (more complex m5)
anova(m5, m6, test = "Chisq")

```

<br>

Comparison between *m5* and a model without Bene_Avg_Age^2 (called *m7*) indicate significantly better fit for *m5*. *m5* is retained as the baseline model.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Remove age squared
m7 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = gm2019)

# Not statsig different, so remove squared prop white
anova(m5, m7, test = "Chisq")


```

<br>

***

### AIC comparisons

The AIC table below indicates that 51% of the model weight is carried by *m5*. Further, the AIC difference between *m5* and the next best model (*m3*) is greater than two, indicating a significantly better fit for *m5*.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Snipped showing how to report AIC results from (https://www.scribbr.com/statistics/akaike-information-criterion/):
# "We used AIC model selection to distinguish among a set of possible models describing the relationship between age, sex, sweetened beverage consumption, and body mass index. The best-fit model, carrying 96% of the cumulative model weight, included every parameter with no interaction effects."

# Another snippet: "If a model is more than 2 AIC units lower than another, then it is considered significantly better than that model."

# AIC: can I just do all models at once. Shows that m5 gets 51% of weight, with m3 and m2 each getting 18%.
mod_list <- list("m1" = m1, "m2" = m2, "m3" = m3, "m4" = m4, "m5" = m5,
                 "m6" = m6, "m7" = m7)
aictab(cand.set = mod_list)

# Confidence set. Looks like this just returns the set of models where weight sums to >= 95% (or whatever the confidence level is set to).
# confset(cand.set = mod_list)

# Evidence ratios. Indicates that m5 is 2.79 times more parsimonious than m3 (the next best model).
# aic_table <- aictab(cand.set = mod_list)
# evidence(aic.table = aic_table)

```

<br>

***

### Final model

The final model (*m5*) is shown below. All higher order terms that did not improve model fit have been removed. All remaining terms except for Prscrbr_RUCA_fct8 are statistically significant.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.width = 5, fig.height = 4}

# m5 summary
m5.sum <- m5 %>%
    tidy() %>%
    mutate(across(matches("estimate|std.error|statistic"),
                  ~ as.character(round(., digits = 2))),
           p.value = format(p.value, scientific = TRUE, digits = 2))

# First 8 terms
m5.sum %>%
    filter(row_number() %in% 1:8) %>%
    datatable(
        rownames = FALSE,
        colnames = c("Term", "Estimate", "SE", "t", "p"),
        options = list(dom = "t",
                       pageLength = nrow(m5 %>% tidy())))

# Last 7 terms
m5.sum %>%
    filter(row_number() %in% 9:nrow(m5.sum)) %>%
    datatable(
        rownames = FALSE,
        colnames = c("Term", "Estimate", "SE", "t", "p"),
        options = list(dom = "t",
                       pageLength = nrow(m5 %>% tidy())))

# Fit separate models by year using the same set of predictors, collect fitted
# values.
years <- gm %>% pull(Year) %>% unique()
fit_gm_year <- map_dfr(years, function(year) {
    data <- gm %>%
        filter(Year == !!year,
               Prscrbr_County != "Not ID")
    fit <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = data)
    data %>%
        mutate(fitted_log_claims_1k = fitted(fit),
               fitted_claims_1k = exp(fitted_log_claims_1k))
})

gm2019 <- fit_gm_year %>%
    filter(Year == 2019)

# Figure of fitted versus observed values
min_axis <- if_else(min(gm2019$fitted_log_claims_1k) < min(gm2019$log_claims_1k),
                    min(gm2019$fitted_log_claims_1k), min(gm2019$log_claims_1k))
max_axis <- if_else(max(gm2019$fitted_log_claims_1k) > max(gm2019$log_claims_1k),
                    max(gm2019$fitted_log_claims_1k), max(gm2019$log_claims_1k))
rsq <- format(glance(m5) %>% pull(r.squared), digits = 2, nsmall = 2)
gm2019 %>%
    ggplot(aes(x = fitted_log_claims_1k, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    scale_x_continuous(limits = c(min_axis, max_axis)) +
    scale_y_continuous(limits = c(min_axis, max_axis)) +
    labs(subtitle = paste0("N = ", nrow(gm2019), ", r-squared = ", rsq),
         x = "Fitted prescribing rate",
         y = "Observed\nprescribing\nrate")

# Model with linear terms only
m8 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       Bene_Prop_White,
   data = gm2019)

```

<br>

***

### Linear terms only

The AIC comparison below indicates that a simpler model with linear terms only---called *m8*---carries 0% of the weight when compared to *m5*.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# AIC
mod_list <- list("m1" = m1, "m2" = m2, "m3" = m3, "m4" = m4, "m5" = m5,
                 "m6" = m6, "m7" = m7, "m8" = m8)
aictab(cand.set = mod_list)

```

*m5* and *m8* have r-squared values of `r round(glance(m5)$r.squared, digits = 2)` and `r round(glance(m8)$r.squared, digits = 2)`, respectively.

<br>

***

## Fits by year

The final model specification was used to fit a series of models---one per year---to data from general medicine providers. Residuals plots and r-squared values for each model are provided below. Residuals for each year appear to be randomly distributed. R-squared values range from 0.14 to 0.20.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Models of general medicine data by year
years <- gm %>%
    count(Year) %>%
    pull(Year)
by_year_gm <- map(years, function(year) {
    data <- gm %>%
        filter(Year == !!year)
    year <- unique(data$Year)
    type <- unique(data$Prscrbr_Type_Std)
    fit <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       I(Prscrbr_RUCA^2) +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
       data = data)
    observed <- data$log_claims_1k
    fitted <- fitted(fit)
    max_axis <- max(c(observed, fitted))
    min_axis <- min(c(observed, fitted))
    residual <-  residuals(fit)
    rsq <- round(summary(fit)$r.squared, digits = 2)
    resid_plot <- tibble(fitted = fitted, residual = residual) %>%
        ggplot(aes(x = fitted, y = residual)) +
        geom_point(alpha = 0.2) +
        labs(title = paste(year, type),
             subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
             x = "Fitted log(Claims per 1K Beneficiaries)",
             y = "Residual\nlog(Claims\nper 1K Beneficiaries)")
    # fit_plot <- tibble(observed = observed, fitted = fitted) %>%
    #     ggplot(aes(x = fitted, y = observed)) +
    #     geom_point(alpha = 0.2) +
    #     geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
    #     scale_x_continuous(limits = c(min_axis, max_axis)) +
    #     scale_y_continuous(limits = c(min_axis, max_axis)) +
    #     labs(title = paste(year, type),
    #          subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
    #          x = "Fitted log(Claims/1K Beneficiaries)",
    #          y = "Observed\nlog(Claims/1K Beneficiaries)")
    # fit_list = list(resid = resid_plot, fit = fit_plot)
    # fit_list
    resid_plot
})
names(by_year_gm) <- years
by_year_gm

```

<br>

***

## Coefficients by year

The figure below indicates that coefficients for models fit to general medicine data are relatively stable across years.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 10}

# Next question is how stable these coefficients are across years. Actually pretty stable, suggesting that we're looking at similar effects across all years in the dataset.
by_year_gm_coef <- map_dfr(years, function(year) {
    data <- gm %>%
        filter(Year == !!year)
    year <- unique(data$Year)
    type <- unique(data$Prscrbr_Type_Std)
    message(paste0("Fitting ", year))
    lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       I(Prscrbr_RUCA^2) +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
       data = data) %>%
        tidy() %>%
        mutate(year = !!year)
})

# Figure
by_year_gm_coef %>%
    filter(term != "(Intercept)") %>%
    ggplot(aes(x = year, y = estimate, group = term, color = term,
               fill = term)) +
    geom_line() +
    geom_ribbon(aes(ymin = estimate - std.error, ymax = estimate + std.error),
                alpha = 0.2, linetype = 0) +
    scale_x_continuous(breaks = seq(2013, 2019, 2)) +
    scale_color_discrete(guide = "none") +
    scale_fill_discrete(guide = "none") +
    facet_wrap(~ term) +
    labs(x = "Year", y = "Estimate")


# Next: Do plots showing residuals across years
# Do a section for linear predictors only. First establish that the more complex model is justified according to model comparisons. But give the option of looking at models with only linear predictors.

```

<br>

***

## Validation

Here I'm focusing on the out-of-sample predictive validity of *m5*---which includes squared and cubed terms---versus *m8*---which includes linear terms only. Both models were trained on 2019 data, then tested on their ability to predict log(claims_1k) for the years 2013-2018. The figure below indicates that predictions from *m5* have consistently lower RMSE and higher r-squared than predictions from *m8*.

```{r, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.width = 9, fig.height = 4}

# Validate GM model by training on 2019, testing on 2013-2018. Want to compare
# m5 (model preferred by log-likelihood & AIC comparison) versus m8 (linear
# terms only).

# Training and test sets
train <- p3 %>%
    filter(Year == 2019,
           Prscrbr_Type_Std == "General Medicine")
test <- p3 %>% filter(Year != 2019, Prscrbr_Type_Std == "General Medicine")

# Separate test sets per year
test_2018 <- p3 %>% filter(Year != 2018, Prscrbr_Type_Std == "General Medicine")
test_2017 <- p3 %>% filter(Year != 2017, Prscrbr_Type_Std == "General Medicine")
test_2016 <- p3 %>% filter(Year != 2016, Prscrbr_Type_Std == "General Medicine")
test_2015 <- p3 %>% filter(Year != 2015, Prscrbr_Type_Std == "General Medicine")
test_2014 <- p3 %>% filter(Year != 2014, Prscrbr_Type_Std == "General Medicine")
test_2013 <- p3 %>% filter(Year != 2013, Prscrbr_Type_Std == "General Medicine")

# Model specification & engine
lm_model <- linear_reg() %>%
    set_engine("lm")

# Fit m5
fit_m5 <- lm_model %>%
    fit(log_claims_1k ~ 1 +
       # Prscrbr_RUCA_fct +
       Prscrbr_RUCA +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
       data = train)

# Fit m8
fit_m8 <- lm_model %>%
    fit(log_claims_1k ~ 1 +
       # Prscrbr_RUCA_fct +
       Prscrbr_RUCA +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       Bene_Prop_White,
       data = train)

# Store test set predictions from each model
test$m5_pred <- predict(fit_m5, new_data = test) %>% pull(.pred)
test$m8_pred <- predict(fit_m8, new_data = test) %>% pull(.pred)

# Predictions per year
test_2018$m5_pred <- predict(fit_m5, new_data = test_2018) %>% pull(.pred)
test_2018$m8_pred <- predict(fit_m8, new_data = test_2018) %>% pull(.pred)
test_2017$m5_pred <- predict(fit_m5, new_data = test_2017) %>% pull(.pred)
test_2017$m8_pred <- predict(fit_m8, new_data = test_2017) %>% pull(.pred)
test_2016$m5_pred <- predict(fit_m5, new_data = test_2016) %>% pull(.pred)
test_2016$m8_pred <- predict(fit_m8, new_data = test_2016) %>% pull(.pred)
test_2015$m5_pred <- predict(fit_m5, new_data = test_2015) %>% pull(.pred)
test_2015$m8_pred <- predict(fit_m8, new_data = test_2015) %>% pull(.pred)
test_2014$m5_pred <- predict(fit_m5, new_data = test_2014) %>% pull(.pred)
test_2014$m8_pred <- predict(fit_m8, new_data = test_2014) %>% pull(.pred)
test_2013$m5_pred <- predict(fit_m5, new_data = test_2013) %>% pull(.pred)
test_2013$m8_pred <- predict(fit_m8, new_data = test_2013) %>% pull(.pred)

# m5 has lower error (rmse & mae) and higher rsq than m8, indicating better
# out-of-sample predictive accuracy when squared and cubed terms are included.
# metrics(test, log_claims_1k, m5_pred)
# metrics(test, log_claims_1k, m8_pred)

# Per year metrics
bind_rows(
metrics(test_2018, log_claims_1k, m5_pred) %>% mutate(Year = 2018, model = "m5"),
metrics(test_2018, log_claims_1k, m8_pred) %>% mutate(Year = 2018, model = "m8"),
metrics(test_2017, log_claims_1k, m5_pred) %>% mutate(Year = 2017, model = "m5"),
metrics(test_2017, log_claims_1k, m8_pred) %>% mutate(Year = 2017, model = "m8"),
metrics(test_2016, log_claims_1k, m5_pred) %>% mutate(Year = 2016, model = "m5"),
metrics(test_2016, log_claims_1k, m8_pred) %>% mutate(Year = 2016, model = "m8"),
metrics(test_2015, log_claims_1k, m5_pred) %>% mutate(Year = 2015, model = "m5"),
metrics(test_2015, log_claims_1k, m8_pred) %>% mutate(Year = 2015, model = "m8"),
metrics(test_2014, log_claims_1k, m5_pred) %>% mutate(Year = 2014, model = "m5"),
metrics(test_2014, log_claims_1k, m8_pred) %>% mutate(Year = 2014, model = "m8"),
metrics(test_2013, log_claims_1k, m5_pred) %>% mutate(Year = 2013, model = "m5"),
metrics(test_2013, log_claims_1k, m8_pred) %>% mutate(Year = 2013, model = "m8")) %>%
    filter(.metric != "mae") %>%
    mutate(.metric = if_else(.metric == "rmse", "RMSE", "R-Squared")) %>%
    ggplot(aes(x = Year, y = .estimate, group = model, color = model)) +
    geom_line() +
    facet_wrap(~ .metric) +
    scale_color_discrete(name = "Model") +
    labs(y = "Estimate")

```

```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

## 2019 fits by provider type

# 2019 dataset
p2019 <- p3 %>%
    filter(Year == 2019) 

# 2019 provider types with at leaset 100 rows
provider_types <- p2019 %>%
    count(Prscrbr_Type_Std) %>%
    arrange(desc(n)) %>%
    filter(row_number() %in% 1:7) %>%
    pull(Prscrbr_Type_Std)

# Models of 2019 data by provider type
by_type_2019 <- map(provider_types, function(type) {
    data <- p2019 %>%
        filter(Prscrbr_Type_Std == type)
    year <- unique(data$Year)
    fit <- lm(
        log(Antbtc_Tot_Clms) ~ 1 +
            log(Tot_Benes) +
            Prscrbr_RUCA +
            Prscrbr_Gndr +
            Bene_Avg_Risk_Scre +
            Bene_Prop_Fem +
            Bene_Prop_White,
        data = data)
    observed <- log(data$Antbtc_Tot_Clms)
    fitted <- fitted(fit)
    max_axis <- max(c(observed, fitted))
    min_axis <- min(c(observed, fitted))
    residual <-  residuals(fit)
    rsq <- round(summary(fit)$r.squared, digits = 2)
    resid_plot <- tibble(fitted = fitted, residual = residual) %>%
        ggplot(aes(x = fitted, y = residual)) +
        geom_point(alpha = 0.2) +
        labs(title = paste(year, type),
             subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
             x = "Fitted log(Antbtc_Tot_Clms)",
             y = "Residual\nlog(Antbtc_Tot_Clms)")
    fit_plot <- tibble(observed = observed, fitted = fitted) %>%
        ggplot(aes(x = fitted, y = observed)) +
        geom_point(alpha = 0.2) +
        geom_abline(intercept = 0, slope = 1, color = "blue", size = 0.2) +
        scale_x_continuous(limits = c(min_axis, max_axis)) +
        scale_y_continuous(limits = c(min_axis, max_axis)) +
        labs(title = paste(year, type),
             subtitle = paste0("N = ", nrow(data), ", r-squared = ", rsq),
             x = "Fitted log(Antbtc_Tot_Clms)",
             y = "Observed\nlog(Antbtc_Tot_Clms)")
    fit_list = list(resid = resid_plot, fit = fit_plot)
    fit_list
})
names(by_type_2019) <- provider_types
by_type_2019

```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

## General medicine coefficients for 2019

# 2019 general medicine data
gm2019 <- gm %>%
    filter(Year == 2019)

# Table of model coefficients
lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       I(Prscrbr_RUCA^2) +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
       data = gm2019) %>%
    tidy() %>%
    mutate(across(matches("estimate|error|statistic|value"),
                  ~ format(., digits = 2, scientific = TRUE))) %>%
    datatable(rownames = FALSE,
              options = list(dom = "t",
                             pageLength = ncol(gm2019)))


# Much less good at predicting claims 1k versus just claims. Probably because now we essentially have to predict two different outcomes: claims and beneficiaries.
m1 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       Bene_Prop_White,
   data = gm2019)
# summary(m1)

# Full model, based on what we saw in univarite plots

```


```{r, eval = FALSE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.height = 8, fig.width = 8}

# <br>
# 
# ***
# 
# ## 2019 coefficients by provider type
# 
# Coefficients show some variability across provider types for models fit to 2019 data.

# Table of coefficients
by_type_2019_coef <- map_dfr(provider_types, function(type) {
    data <- p2019 %>%
        filter(Prscrbr_Type_Std == !!type)
    year <- unique(data$year)
    type <- unique(data$Prscrbr_Type_Std)
    lm(log(Antbtc_Tot_Clms) ~ 1 +
            log(Tot_Benes) +
            Prscrbr_RUCA +
            Prscrbr_Gndr +
            Bene_Avg_Risk_Scre +
            Bene_Prop_Fem +
            Bene_Prop_White,
        data = data) %>%
        tidy() %>%
        mutate(Prscrbr_Type_Std = !!type)
})

# Figure
by_type_2019_coef %>%
    ggplot(aes(x = Prscrbr_Type_Std, y = estimate, group = term,
               color = term, fill = term)) +
    geom_line() +
    geom_ribbon(aes(ymin = estimate - std.error, ymax = estimate + std.error),
                alpha = 0.2, linetype = 0) +
    labs(x = "Provider\nType", y = "Estimate") +
    coord_flip() +
    scale_color_discrete(guide = "none") +
    scale_fill_discrete(guide = "none") +
    facet_wrap(~ term)
    

```

<br>

***

## Maps

### Observed

This map shows county-related differences in anbitiotic prescribing rates. Lighter colors represent higher prescribing rates (claims per 1K beneficiaries).

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Write table of 2019 general medicine OE ratios to Box
gm2019_oe <- fit_gm_year %>%
    filter(Year == 2019) %>%
    mutate(oe = claims_1k / fitted_claims_1k)

# Compute O/E by year and county. 39 counties represented.
county_yr_oe <- fit_gm_year %>%
    filter(Prscrbr_County != "Not ID") %>%
    mutate(oe = claims_1k / fitted_claims_1k) %>%
    group_by(Year, Prscrbr_County) %>%
    summarize(n_oe = sum(!is.na(oe)),
              mean_oe = mean(oe, na.rm = TRUE),
              n_o = sum(!is.na(claims_1k)),
              mean_o = mean(claims_1k, na.rm = TRUE), .groups = "drop")

# Get county shapes and join in OEs. This data structure can have NAs in the mean column, but if there are NAs in any other columns it will cause the county to not be plotted, rather than being plotted gray (no data).
counties_sf <- counties(state = "ID", cb = FALSE) %>%
    left_join(county_yr_oe %>%
                  filter(Year == 2019) %>%
                  select(NAMELSAD = Prscrbr_County, n_oe, mean_oe, n_o, mean_o),
              by = "NAMELSAD") %>%
    mutate(n_oe = if_else(is.na(n_oe), 0L, n_oe),
           n_o = if_else(is.na(n_o), 0L, n_o),
           County = NAME)

# US county shapes
counties <- rjson::fromJSON(file = "https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json")

# US county FIPS
df <- read.csv(
    "https://raw.githubusercontent.com/plotly/datasets/master/fips-unemp-16.csv",
    colClasses = c(fips = "character")) %>%
    as_tibble() %>%
    select(fips)

df2 <- tibble(fips = counties_sf$COUNTYFP,
              state = counties_sf$STATEFP,
              county = counties_sf$NAME,
              mean = counties_sf$mean_o,
              N = counties_sf$n_o) %>%
    mutate(fips = paste0(state, fips)) %>%
    select(fips, county, state, mean, N)

# Join Idaho-specific info to df--the table with all US county FIPS
df3 <- df %>%
    left_join(df2, by = "fips") %>%
    mutate(hover_text = paste0(
        county, "<br>",
        "N = ", N, "<br>",
        "Claims/1K  = ", round(mean, digits = 2)),
        NA_trace = if_else(is.na(mean) & state == "16", 1L, NA_integer_))

# Figure
plot_ly() %>%
    
    # Trace for counties with defined O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$mean,
        zmin = min(df3$mean),
        zmax = max(df3$mean),
        text = df3$hover_text,
        hoverinfo = "text",
        colorscale = "Viridis",
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    
    # Trace for counties with NA O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$NA_trace,
        text = df3$hover_text,
        hoverinfo = "text",
        
        # Counties with missing values will be gray, but scale won't be shown
        colorscale = "Greys",
        showscale = FALSE,
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    colorbar(title = "Observed\nClaims per 1K\nBeneficiaries",
             outlinewidth = 0,
             thickness = 30) %>%
    plotly::layout(mapbox = list(
        style = "carto-positron",
        zoom = 4.6,
        center = list(lon = -114, lat = 45.6)))

```

<br>

***

### Observed/Expected

This map shows county-related differences in antibiotic prescribing rates after controlling for provider gender and rurality, and beneficiary age, health status, proportion female, and proportion white.

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

# Read in address info
# address_county <- read_feather("Address-query-county bank.feather")

# Loop over general medicine to fit models by year

# Table of Idaho county FIPS, county names, log(O/E).
# NOTE: Better if I get this info from counties JSON. Then I don't need to use
# tigris at all.
df2 <- tibble(fips = counties_sf$COUNTYFP,
              state = counties_sf$STATEFP,
              county = counties_sf$NAME,
              mean = counties_sf$mean_oe,
              N = counties_sf$n_oe) %>%
    mutate(fips = paste0(state, fips)) %>%
    select(fips, county, state, mean, N)

# Join Idaho-specific info to df--the table with all US county FIPS
df3 <- df %>%
    left_join(df2, by = "fips") %>%
    mutate(hover_text = paste0(
        county, "<br>",
        "N = ", N, "<br>",
        "O/E Claims/1K = ", round(mean, digits = 2)),
        NA_trace = if_else(is.na(mean) & state == "16", 1L, NA_integer_))

# Figure
plot_ly() %>%
    
    # Trace for counties with defined O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$mean,
        zmin = min(df3$mean),
        zmax = max(df3$mean),
        text = df3$hover_text,
        hoverinfo = "text",
        colorscale = "Viridis",
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    
    # Trace for counties with NA O/E
    add_trace(
        type = "choroplethmapbox",
        geojson = counties,
        locations = df3$fips,
        z = df3$NA_trace,
        text = df3$hover_text,
        hoverinfo = "text",
        
        # Counties with missing values will be gray, but scale won't be shown
        colorscale = "Greys",
        showscale = FALSE,
        marker = list(line = list(width = 0),
                      opacity = 0.5)) %>%
    colorbar(title = "Observed/Expected\nClaims per 1K\nBeneficiaries",
             outlinewidth = 0,
             thickness = 30) %>%
    plotly::layout(mapbox = list(
        style = "carto-positron",
        zoom = 4.6,
        center = list(lon = -114, lat = 45.6)))

```

<br>

***

## 2019 caterpillar plot

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.width = 11}

# 2019 general medicine dotplot
gm2019 <- fit_gm_year %>%
    filter(Year == 2019) %>%
    mutate(oe = claims_1k / fitted_claims_1k,
           Prscrbr_NPI = fct_reorder(Prscrbr_NPI, -oe))
gm2019 %>%
    filter(oe < 6) %>%
    ggplot(aes(x = Prscrbr_NPI, y = oe)) +
    geom_point(color = "dodgerblue", alpha = .2) +
    geom_hline(yintercept = 1, linetype = "dashed", size = .2) +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          panel.grid.major.x = element_blank()) +
    labs(title = "Standardized Prescribing Ratios for 2019 Idaho General Medicine Providers",
         subtitle = paste("N =", nrow(gm2019)),
         x = "Provider",
         y = "Observed/Expected\nClaims per 1K\nBeneficiaries")
ggsave("figures/General medicine 2019 dot.png", height = 5, width = 11)

# 2019 general medicine barplot
gm2019 <- fit_gm_year %>%
    filter(Year == 2019) %>%
    mutate(oe = claims_1k / fitted_claims_1k,
           Prscrbr_NPI = fct_reorder(Prscrbr_NPI, -oe))
gm2019 %>%
    filter(oe < 6) %>%
    ggplot(aes(x = Prscrbr_NPI, y = oe)) +
    geom_col(fill = "dodgerblue", alpha = .5) +
    geom_hline(yintercept = 1, linetype = "dashed", size = .2) +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          panel.grid.major.x = element_blank()) +
    labs(title = "Standardized Prescribing Ratios for 2019 Idaho General Medicine Providers",
         subtitle = paste("N =", nrow(gm2019)),
         x = "Provider",
         y = "Observed/Expected\nClaims per 1K\nBeneficiaries")
ggsave("figures/General medicine 2019 bar.png", height = 5, width = 11)

```

<br>

***

# Emergency medicine

```{r, eval = TRUE, echo = TRUE, error = FALSE, message = FALSE, warning = FALSE}

# Place names based on Google API
places <- read_feather("Address-name bank.feather") %>%
    select(place = name, dataset_address)

# Emergency medicine providers, all years
em <- p3 %>%
    filter(Prscrbr_Type_Std == "Emergency Medicine")

# 2019 emergency medicine with place names joined in
em2019 <- em %>%
    filter(Year == 2019) %>%
    left_join(places, by = "dataset_address")
    
# Counts of emergency medicine places
em2019 %>%
    count(place) %>%
    arrange(desc(n))

# Add categorization of places. This is just a partial coding of the places that
# occur more often. Could do more.
em2019 <- em2019 %>%
    mutate(org = case_when(
        str_detect(place, "Luke") ~ "St. Luke's",
        str_detect(place, "Alphonsus") ~ "St. Alphonsus",
        str_detect(place, "Portneuf") ~ "Portneuf",
        str_detect(place, "Kootenai") ~ "Kootenai",
        str_detect(place, "EIRMC") ~ "EIRMC",
        str_detect(place, "Joseph") ~ "St. Joseph",
        str_detect(place, "Madison") ~ "Madison Memorial",
        str_detect(place, "Bonner") ~ "Bonner General Health",
        str_detect(place, "Boundary") ~ "Boundary Community Hospital",
        str_detect(place, "Cassia") ~ "Cassia Regional Hospital",
        TRUE ~ "Other"))

# Orgs with >= 5 emergency medicine providers
orgs <- em2019 %>%
    count(org) %>%
    arrange(desc(n)) %>%
    filter(n >= 5,
           org != "Other") %>%
    pull(org)

# Counts for largest orgs. There are only seven with >= 5 providers.
em2019 %>%
    filter(org %in% orgs) %>%
    count(org) %>%
    arrange(desc(n))

# Visualize org diffs
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = org, y = log_claims_1k)) +
    geom_boxplot() +
    coord_flip()

```


```{r, eval = TRUE, echo = TRUE, error = FALSE, message = FALSE, warning = FALSE, fig.height = 5, fig.width = 10}

# Same as above, but claims 1k rather than log(claims 1k)
em2019 %>%
    filter(org %in% orgs) %>%
    left_join(em2019 %>%
                  filter(org %in% orgs) %>%
                  count(org), by = "org") %>%
    mutate(org = paste0(org, "\nN = ", n),
           org = fct_reorder(org, claims_1k)) %>%
    
    ggplot(aes(x = org, y = claims_1k)) +
    geom_boxplot() +
    coord_flip() +
    theme(axis.title.y = element_blank()) +
    labs(title = "2019 emergency medicine antibiotic prescribing rate by healthcare system",
         y = "Claims per 1K beneficiaries")
ggsave("figures/2019 emergency medicine antibiotic prescribing rate by healthcare system.png", height = 5, width = 11)

```

```{r, eval = TRUE, echo = TRUE, error = FALSE, message = FALSE, warning = FALSE}

# Simple model of log_claims_1k ~ org, with Madison Memorial--the org with the lowest median--set to baseline. Results show that even the level with the highest median--Portneuf--isn't statistically different from baseline, p = 0.29.

# Data
em2019.2 <- em2019 %>%
    filter(org %in% orgs) %>%
    mutate(org = fct_relevel(org, "Kootenai"))

# Dummy coding for org with contrasts for each level versus Kootenai. Choosing
# Kootenai as the baseline since it has nearly the lowest median and a fair
# amount of data. Shows that both Portneuf andSt. Al's have statistically higher
# prescribing rates, p = 0.034 and p = 0.036, respectively. The St. Al's result might be driven by three outliers (see figure).
lm(log_claims_1k ~ 1 + org, data = em2019.2) %>%
    summary()

# Alternatively, set up weighted effects coding where each level is compared to
# the grand mean. Shows that Kootenai is marginally lower than the grand mean, p
# = 0.052. All other comparisons are null.
contrasts(em2019.2$org) <- contr.wec(em2019.2$org, omitted = "Madison Memorial")
lm(log_claims_1k ~ 1 + org, data = em2019.2) %>%
    summary()

# Look at bivariate relationships
# RUCA
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Prscrbr_RUCA_fct, y = log_claims_1k)) +
    geom_boxplot()

# Provider gender
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Prscrbr_Gndr, y = log_claims_1k)) +
    geom_boxplot()

# Bene HCC. Maybe squared and cubed terms
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Avg_Risk_Scre, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Bene age. Maybe squared and cubed terms
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Avg_Age, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Bene prop female. Squared term
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Prop_Fem, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Bene prop white. Squared term
em2019 %>%
    filter(org %in% orgs) %>%
    ggplot(aes(x = Bene_Prop_White, y = log_claims_1k)) +
    geom_point(alpha = 0.2) +
    geom_smooth()

# Full model
em1 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       I(Bene_Avg_Age^3) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = em2019 %>%
       filter(org %in% orgs))
summary(em1)

# Evidence to drop cubed age
em2 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em1, em2, test = "Chisq")

# Evidence to retain cubed HCC
em3 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White +
       I(Bene_Prop_White^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em2, em3, test = "Chisq")

# Evidence to drop white squared
em4 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em2, em4, test = "Chisq")

# Evidence to retain female squared
em5 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       I(Bene_Avg_Age^2) +
       Bene_Prop_Fem +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em4, em5, test = "Chisq")

# Evidence to drop squared age
em6 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Prscrbr_Gndr +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em4, em6, test = "Chisq")

# Evidence to drop provider gender
em7 <- lm(log_claims_1k ~ 1 +
       org +
       Prscrbr_RUCA_fct +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em6, em7, test = "Chisq")

# Evidence to drop org
em8 <- lm(log_claims_1k ~ 1 +
       Prscrbr_RUCA_fct +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em7, em8, test = "Chisq")

# Evidence to drop RUCA
em9 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Avg_Age +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em8, em9, test = "Chisq")

# Evidence to drop age
em10 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2) +
       Bene_Prop_White,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em9, em10, test = "Chisq")

# Evidence to drop white
em11 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em10, em11, test = "Chisq")

# Check cubed HCC again. Evidence still indicates it should be kept.
em12 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       Bene_Prop_Fem +
       I(Bene_Prop_Fem^2),
   data = em2019 %>%
       filter(org %in% orgs))
anova(em11, em12, test = "Chisq")

# Check squared fem again. Evidence still indicates it should be
# kept--marginally improves fit..
em13 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       I(Bene_Avg_Risk_Scre^2) +
       I(Bene_Avg_Risk_Scre^3) +
       Bene_Prop_Fem,
   data = em2019 %>%
       filter(org %in% orgs))
anova(em11, em13, test = "Chisq")

# Final model
summary(em11)

# Check residuals. Look okay
tibble(fitted = fitted(em11),
       residual = residuals(em11)) %>%
    ggplot(aes (x = fitted, y = residual)) +
    geom_point(alpha = 0.25)

# Note that even though we dropped org from the final model it could still be
# that orgs (e.g., St. Luke's versus St. Al's) matter in interaction with other
# predictors.

```

<br>

***

## AIC comparisons

Although *em11* accounts for the most model weight, the next two models---*em10* and *em9* are both within two units. 

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

em_mod_list <- list(
    "em1" = em1, "em2" = em2, "em3" = em3, "em4" = em4, "em5" = em5,
    "em6" = em6, "em7" = em7,"em8" = em8, "em9" = em9, "em10" = em10,
    "em11" = em11)
aictab(cand.set = em_mod_list)

```

<br>

When comparing *em11* versus a model with linear terms only (*em14*) we see that *em11* is heavily favored:

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

em14 <- lm(log_claims_1k ~ 1 +
       Bene_Avg_Risk_Scre +
       Bene_Prop_Fem,
   data = em2019 %>%
       filter(org %in% orgs))

# All candidates
em_mod_list <- list(
    "em1" = em1, "em2" = em2, "em3" = em3, "em4" = em4, "em5" = em5,
    "em6" = em6, "em7" = em7,"em8" = em8, "em9" = em9, "em10" = em10,
    "em11" = em11, "em14" = em14)
aictab(cand.set = em_mod_list)

# Just 11 versus 14
em_mod_list <- list("em11" = em11, "em14" = em14)
aictab(cand.set = em_mod_list)

```

<br>

*em11* also fits the training data better:

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE}

bind_rows(
    glance(em11) %>%
        mutate(model = "em11"),
    glance(em14) %>%
        mutate(model = "em14")) %>%
    select(model, r.squared)

```

<br>

***

## 2019 caterpillar

```{r, eval = TRUE, echo = FALSE, error = FALSE, message = FALSE, warning = FALSE, fig.width = 11}

# 2019 emergency medicine
# Add in fitted and compute OE
em2019.1 <- em2019 %>%
       filter(org %in% orgs)
em2019.1$fitted_log_claims_1k <- fitted(em11)
em2019.1 <- em2019.1 %>%
    mutate(fitted_claims_1k = exp(fitted_log_claims_1k),
           oe = claims_1k / fitted_claims_1k)

# Table of 2019 emergency medicine OE ratios
em2019_oe <- em2019.1 %>%
    filter(Year == 2019)

# Write list of named dataframes to excel. These will end up as separate tabs.
list("General Medicine" = gm2019_oe %>%
         select(Year:Prscrbr_RUCA, Prscrbr_Gndr,
                Prscrbr_Address = dataset_address, Prscrbr_County:claims_1k,
                fitted_claims_1k, OE_ratio = oe),
     "Emergency Medicine" = em2019_oe %>%
         select(Year:Prscrbr_RUCA, Prscrbr_Gndr,
                Prscrbr_Address = dataset_address, Prscrbr_County:claims_1k,
                fitted_claims_1k, OE_ratio = oe)) %>%
    write_xlsx(paste0(box_dir, "Idaho 2019 OE ratios.xlsx"))

# Dotplot
em2019.1 %>%
    mutate(Prscrbr_NPI = fct_reorder(Prscrbr_NPI, -oe)) %>%
    ggplot(aes(x = Prscrbr_NPI, y = oe)) +
    geom_point(color = "dodgerblue", alpha = 0.5) +
    geom_hline(yintercept = 1, linetype = "dashed", size = .2) +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          panel.grid.major.x = element_blank()) +
    labs(title = "Standardized Prescribing Ratios for 2019 Idaho Emergency Medicine Providers",
         subtitle = paste("N =", nrow(em2019.1)),
         x = "Provider",
         y = "Observed/Expected\nClaims per 1K\nBeneficiaries")
ggsave("figures/Emergency medicine 2019 dot.png", height = 5,
       width = 11)

# Barplot
em2019.1 %>%
    mutate(fitted_claims_1k = exp(fitted_log_claims_1k),
           oe = claims_1k / fitted_claims_1k,
           Prscrbr_NPI = fct_reorder(Prscrbr_NPI, -oe)) %>%
    ggplot(aes(x = Prscrbr_NPI, y = oe)) +
    geom_col(fill = "dodgerblue", alpha = .5) +
    geom_hline(yintercept = 1, linetype = "dashed", size = .2) +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          panel.grid.major.x = element_blank()) +
    labs(title = "Standardized Prescribing Ratios for 2019 Idaho Emergency Medicine Providers",
         subtitle = paste("N =", nrow(em2019.1)),
         x = "Provider",
         y = "Observed/Expected\nClaims per 1K\nBeneficiaries")
ggsave("figures/Emergency medicine 2019 bar.png", height = 5,
       width = 11)

```

